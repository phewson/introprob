\documentclass{book}
\title{Probability with Applications: Course Notes}
\author{Paul Hewson and Malgorzata Wojtys}
\date{February - May 2016}
\usepackage{amsmath,amssymb,amsfonts,graphics,hyperref,color,setspace,synttree,keystroke}
\usepackage{calculator}

\usepackage{longtable}
\usepackage{a4wide,color,Sweave,url,verbatim,xargs,longtable}
\usepackage{tikz}
\newenvironment{question}{\item \textbf{Problem}\newline}{}
\newenvironment{solution}{\comment}{\endcomment}
\newenvironment{answerlist}{\renewcommand{\labelenumi}{(\alph{enumi})}\begin{enumerate}}{\end{enumerate}}
\newtheorem{df}{Definition}[section]

\begin{document}
\sffamily
\onehalfspacing

\maketitle

\chapter{Background to the course and course administration}

\section{How you will be assessed}

\begin{itemize}
\item 2 hour Exam (70\%)
\item Coursework (30\%)
\end{itemize}

The coursework will consist of a mixture of exam type questions which you can complete electronically on Moodle as well as a small activity that you have to write up and also submit to Moodle.

\section{How you pass the assessment}

We set a lot of problems, which you should attempt.   You will be given chances in computer labs to attempt some problems where you can ask for clarification if needs be.   The problems we do in class are the same kind of problems as you get on the exam.

\section{Why study probability?}

There is a perception (often gained by taking A level modules) that probability is statistics.   Please don't confuse the two.   Statistics is a process of drawing inference about a population from a sample of data, and yes, it uses many techniques from various branches of mathematics including probability.   But probability is a mathematical field in its own right, the logic of uncertainty.   There are various reasons for studying probability:

\begin{itemize}
\item In order to gain a mature mathematical understanding of statistical inference
\item In order to understand physics (and particularly quantum physics)
\item In order to develop various computer science algorithms, such as the so-called Monte Carlo methods
\item In order to understand gambling and finance (I believe these are separate topics, but there are lucrative careers to be made as an actuary)
\item Applied probability in its own right
\end{itemize}

This module is intended as a formal introduction to the branch of mathematics known as probabilty.   We will illustrate applied probability where possible to keep the module alive.   It is \emph{not} a course in statistics.   Discrete probability allows you to use some very simple arithmetic to solve some very baffling problems and is a good way of developing rigorous mathematical reasoning skills.   Probability generally touches on several branches of mathematics and this course will give you the opportunity to practice your skills in areas such as calculus.

\section{Background Definitions}

There is a fascinating philosophical / linguistic / epistemological history behind the concept of probability.   For our purposes, \emph{Probability} is nothing more than a number between $0$ and $1$ that behaves in accordance with three axioms.   However, you can do a lot with numbers.   You can think of probability as being:

\begin{itemize}
\item A symmetrical thing (the coin has two faces, heads and tails)
\item A long run frequency thing (out of 10,000 coin tosses, 5,023 were heads)
\item A subjective thing (that person is obvious a crook and if they want me to bet on tails it is very likely they have a rigged coin)
\end{itemize}




\chapter{Brief review of Sets}






\subsubsection{Set theory notation}

% I might not cover this in a lecture, we need the first six rows at the moment, the rest are only needed if we were going to do a lot of proofs and some very formal probability theory.
 
% For completeness, we quote a table from Grimmett and Stirzaker (2004) which gives a listing of set theory and probability theory notation.\\[0.5in]

% {\color{blue}
% \begin{footnotesize}
% \begin{tabular}{lll}
% Notation & Set theory & Probability Theory \\
% \hline
% $\Omega$ & A collection of objects & Sample space \\
% $\omega$ & A subset of $\Omega$ & Elementary event/outcome\\
% $A$ & A subset of $\Omega$ & Event that some condition $A$ occurs \\
% $A^C$ & Complement of $A$ & No event $A$ occurs \\
% $A \cap B$ & Intersection of $A$ and $B$ & Both $A$ and $B$ occur \\
% $A \cup B$ & Union of $A$ and $B$ & Either $A$ occurs, or $B$ occurs or both
% \\
% $A \setminus B$ & Difference & $A$ occurs but $B$ does not occur \\
% $ A \bigtriangleup B $ & Symmetric difference & Either A or B but not both \\
% $A \subseteq B$ & Inclusion & If $A$ occurs then $B$ occurs \\
% $\emptyset$ & Empty set & Impossible event \\
% $\Omega$ & Whole space & Certain event
% \end{tabular}
% \end{footnotesize}
% }




\section{Sample spaces: how we use Sets}

\textit{More information is given in Section 1.2 of Blitzstein and Hwang}

Here are some key definitions:

\fbox{
  \begin{minipage}[c]{1.0\linewidth}
An \emph{experiment} %(esperimento) 
is any process that generates a set of outcomes where the outcome is uncertain.   For a random experiment:

\begin{itemize}
\item The \emph{sample space} $\Omega$ is the set of all possible outcomes 
%(campione di spazio)
\item An \emph{event} is a subset of the sample space 
%(evento)
  \begin{itemize}
  \item A \emph{simple event} is an event which cannot be a union of other events
  \item A \emph{composite event} is an event which is not a simple event
  \end{itemize}
\item The \emph{event space} is the set of all events (evento di spazio)
\end{itemize}
\end{minipage}
}

\subsection{Example}

Consider an experiment in which three coins are tossed.   We are interested in the {\color{red}\emph{event}} that all coins will show the same face. 



The following tree diagram denotes the breakdown of the sample space ($\Omega$).   After the first coin toss we have either a head or a tail.   After the second, for either of the possible outcomes of the first toss we also have a head or tail.   Finally, after the third coin toss, we have a row denoting that a head or tail is possible for any of the previous outcomes. 

%% Cardano was the first person to start thinking about systematically evaluating sample spaces in this way, but he missed a trick in that to him HTH and HHT would be the same (two heads and a tail).   It took nearly 100 years and Galileo to really master the business of sample spaces.  


\subsection{Tree diagram}

\begin{figure}[!h]
\synttree[$\Omega$ [H [H [H][T]][T [H][T]]]  [T [H [H][T]][T [H][T]]]] 
\end{figure}


In total therefore, the tree diagram shows on the bottom row that there are a total of $2^3$ possible outcomes in the sample space.   In other words, there are 8 different ways of travelling though the tree diagram,  resulting in the following outcomes: 
\begin{itemize}
\item {\color{red}HHH}, HHT, HTH, HTT, THH, THT, TTH, {\color{red}TTT}.
\end{itemize}  



 We are interested in the event that all faces are the same.   There are two outcomes in the sample space which correspond to this event - denoted in red.\\[0.25in]   

\fbox{
\begin{minipage}[c]{3.5in}
Recap:
\begin{itemize}
\item {\color{blue}Sample Space} ($\Omega$) - the eight outcomes for the experiment: 
\\{\color{red}HHH}, HHT, HTH, HTT, THH, THT, TTH, {\color{red}TTT}. 
\item {\color{blue}Event} ($A$) - the two outcomes of interest: {\color{red}HHH}, {\color{red}TTT}
\end{itemize}
\end{minipage}
}
\vspace{0.25in}

There are 8 outcomes in our sample space, two of them correspond to the event ``all three coins show the same space''.   If we continue to focus on naive definitions of probability, it pays us to consider Venn diagrams.


% We can form collections $\mathfrak{B}$ of (overlapping or non-overlapping) subsets of our sample space $\Omega$.   There are some restrictions on these collections which must be:

% \begin{itemize}
% \item The empty set $\emptyset$ must be in the collection $\mathfrak{B}$
% \item If $A \in \mathfrak{B}$ then $A^C \in \mathfrak{B}$
% \item If $A_1, A_2, \ldots \in \mathfrak{B}$ then $\cup_{i=1}^\infty A_i \in \mathfrak{B}$
% \end{itemize}

% These might seem trivially obvious for the naive problems, and hopefully we won't need to say any more.   For example, the second condition tells you if you have a world cup final of Argentina versus Germany, you can't say the complement of Argentina winning is Brasil winning however happy Brasilian fans might be with a German victory.


\subsection{Venn diagram}

An alternative method of visualising is via a Venn Diagram.

\begin{center}
\begin{figure}[!h]
\begin{picture}(200,110)
\put(0,0){\framebox(200,110){}}
\qbezier(15,55)(15,105)(65,105)
\qbezier(65,105)(115,105)(115,55)
\qbezier(115,55)(115,5)(65,5)
\qbezier(65,5)(15,5)(15,55)

%\qbezier(80,55)(80,105)(130,105)
%\qbezier(130,105)(180,105)(180,55)
%\qbezier(180,55)(180,5)(130,5)
%\qbezier(130,5)(80,5)(80,55)
\put(5,95){$\Omega$}
\put(40,50){$A$ (HHH, TTT)}
\put(130,50){$A^C$ }
\put(120,30){ (HTH HTH HHT }
\put(120,10){ THT TTH THH)}
%\put(80,50){ $A \cap B$}
\end{picture}
\end{figure}
\end{center}


In this diagram, $A$ denotes the event ``all three faces show the same'', and $A^C$ denotes ``A complement'' (also known as ``not A''), in other words the six outcomes where the faces are not identical.  




\subsection{Multiple events}


\fbox{
\begin{minipage}[c]{1.0\textwidth}
\textbf{Notation}
\begin{itemize}
\item $\cup$ denotes the ``union'' of two sets, e.g., $A \cup B$ is the event that either $A$ occurred, or $B$ occurred or both occurred
\item $\cap$ denotes the ``intersection'' of two sets, e.g. $A \cap B$ is the event that both $A$ and $B$ occurred
\item ``Mutually exclusive"" means that either $A$ can happen, or $B$ but not both
\end{itemize}
\end{minipage}
}

For the same experiment, consider again the event $A$, ``all three coins show the same face''.   But now, consider a second event, $B$, which we define as ``two or more coins show a head''

\begin{itemize}
\item A: {\color{red}HHH}, HHT, HTH, HTT, THH, THT, TTH, {\color{red}TTT}.
\item B: {\color{blue}HHH}, {\color{blue}HHT}, {\color{blue}HTH}, HTT, {\color{blue}THH}, THT, TTH, TTT
\end{itemize}

As before, 2 out the 8 outcomes correspond to event $A$.   We can also see that 4 of the 8 outcomes correspond to event $B$.   We can also see that one outcome (HHH) corresponds to both event $A$ and event $B$.   We can extend the Venn diagram to illustrate this:


\begin{center}
\begin{figure}[!h]
\begin{picture}(200,110)
\put(0,0){\framebox(200,110){}}
\qbezier(15,55)(15,105)(65,105)
\qbezier(65,105)(115,105)(115,55)
\qbezier(115,55)(115,5)(65,5)
\qbezier(65,5)(15,5)(15,55)

\qbezier(80,55)(80,105)(130,105)
\qbezier(130,105)(180,105)(180,55)
\qbezier(180,55)(180,5)(130,5)
\qbezier(130,5)(80,5)(80,55)
\put(5,95){$\Omega$}
\put(40,50){A}
\put(35,35){(TTT)}
\put(130,50){B}
\put(125,35){(THH HTH}
\put(125,20){ HHT)}
\put(80,50){ $A \cap B$}
\put(80,35){ (HHH)}
\end{picture}
\end{figure}
\end{center}



You can see that we use the Venn diagram to visually illustrate that the outcome HHH is in both event A and event B.   Standard set theory notation $A \cap B$ is used to denote that this is an ``intersection''.

\begin{itemize}
\item Which outcomes are in $(A \cup B)^C$?
\end{itemize}
%% don't know what to do here, these are the three events that are in neither A nor B





We should be able to verify standard operations such as:
\begin{itemize}
\item $A \cap B$: HHH
\item $A \cup B$: HHH, TTT, HTH, HHT, THH
\item $B^C$: TTT, TTH, THT, HTT
\item $(A \cup B)^C$: TTH, THT, HTT
\end{itemize}



John Venn has in interesting family background, see \href{http://www-groups.dcs.st-and.ac.uk/history/Biographies/Venn.html}{\color{blue}MacTutor article on John Venn}.

%% I don't think I'd cover this in a lecture

\subsubsection{Commutation and association}

Some mathematical properties of sets.


Commutativity:
\begin{itemize}
\item $A \cup B = B \cup A$
\item $A \cap B  = B \cap A$
\end{itemize}


Associativity:
\begin{itemize}
\item $A \cup B \cup C = (A \cup B) \cup C = A \cup (B \cup C)$
\item $A \cap B \cap C = (A \cap B) \cap C = A \cap (B \cap C)$
\end{itemize}

Distributivity:
\begin{itemize}
\item $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$
\item $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$
\end{itemize}


And De Morgan's laws say:
\begin{itemize}
\item $(A \cup B)^C = A^C \cap B^C$
\item $(A \cap B)^C = A^C \cup B^C$
\end{itemize}



This material will get covered more formally in a pure maths course, hopefully we can see how these can be used as the basis for probability.



\section{Problems}
\begin{enumerate}
\input{Problems/dummy1/Set1_BasicSets.tex}
\input{Problems/dummy1/Set1_SampleSpaces.tex}
\input{Problems/dummy1/Set1_CoinTossing.tex}
\end{enumerate}



\chapter{The naive definition of probability}

\section{Na\'ive definition of Probability}

\textit{This is covered in section 1.3 of Blitzstein and Hwang}

Consider a random experiment with a finite number of outcomes, each with the same probability.   For event $A$, we claim that:

\begin{displaymath}
\mbox{Probability of an event} = \frac{\mbox{Number of possible sample points consistent with this event}}{\mbox{Total number of sample points}}
\end{displaymath}

Or in a better notation:

\begin{equation}
p[A] = \frac{n[A]}{n[\Omega]}
\end{equation}
where $A$ denotes the event we are interested in, $n[A]$ is the number of ways in which $A$ can happen and $n[\Omega]$ is the number of events in the sample space.  


Recall from our first Venn diagram, where we used $A^C$ to denote the \emph{complement} of $A$ (i.e. those outcomes that weren't in $A$), then the probability of $A^C$ (probability that $A$ doesn't happen), $p[A^C]$ is:

\begin{displaymath}
p[A^C] = 1 - p[A]
\end{displaymath}


Likewise, if we consider the second Venn diagram, and consider that $p[B]$ denotes the probability of event $B$ happening we have:

\begin{itemize}
\item $P[A \cup B]$: probability that event $A$ or event $B$, or both happens
\item $P[A \cap B]$: probability that both $A$ and $B$ happen
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% Perms and Combs
%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Counting rules OK}

We've spent a lot of time looking at dice and coins.   If we have $i=1,2,3$ die, each of these three dice can show one of $n_i=6$ faces.   Together the number of possible outcomes are given by $n_1 \times n_2 \times n_3 = 6^3$.   (And using our na\"ive definition of probability we would say each outcome can occur with probability $\frac{1}{6^3}$).   However, drawing tree diagrams to explore the sample space is rather tedious.   We need some ideas that can let us evaluate the number of possible outcomes in a more efficient manner.

For more in depth information see Blitzstein Section 1.4.

 
\fbox{\begin{minipage}[c]{1.0\textwidth}
Nice proof in Baklawski of multiplication rule
\end{minipage}
}


\subsubsection{N-tuple}

So, broadening the problem a little, so that we don't have all $r$ objects with the same size $n$.

\begin{df}
An N-tuple is a finite ordered set with an unspecified number of members
\end{df}

For example, a 5-tuple is an ordered set with 5 members.

Suppose that each outcome (i.e., element) of $A$ takes the form of an n-dimensional vector (or n-tuple) such as ($a_1, a_2, \ldots a_n$).   If there are $N_1$ objects that can be used for $a_1$, and $N_2$ for $a_2$ then:

\begin{equation}
n(A) = N_1N_2 \ldots N_n   
\end{equation}
assuming that sets $A_1, A_2, \ldots A_k$ have respectively $n_1, n_2, \ldots, n_k$ different ways in which one can first take an element of $A_1$, then an element of $A_2$ and so on.


So for our factory problem, we have $N_1 = 15$, $N_2=8$ and $N_3=4$, with $15 \times 8 \times 4 = 480$.  This is rather an intuitive result, but it seems too convenient to be true that we needed exactly one maintenance person, one production person and one supervisor.   




\section{Some common scenarios}

We consider two scenarios:
\begin{itemize}
\item Permutations (the order of the elements is important)
\item Combinations (the order of the elements is not important)
\end{itemize}

Within each scenario, we consider two types of sampling:
\begin{itemize}
\item Sampling with replacement (for example with dice or coins, if we use a second roll/throw, we have the same number of possible outcomes)
\item Sampling without replacement (for example with cards, once we have removed a card from a pack of (say) $n=52$ cards, on the next draw we have $n-1=51$ cards to choose from
\end{itemize}



 



\fbox{\begin{minipage}[c]{1.0\textwidth}
\textbf{Summary of key formulae}

(Do note it's better to be able to derive these from first principles)

\begin{tabular}{lcc}
& With replacement & Without replacement \\
Ordered & $n^k$ & $\frac{n!}{(n-k)!}$ \\
Unordered & $\binom{n+k-1}{k}$ & $\binom{n}{k}$
\end{tabular}

Where $\binom{a}{b}$ denotes $\frac{a!}{b!(a-b)}$

\end{minipage}
}


 


\subsection{Permutation: Ordered sets}



Given a population of $n$ distinct elements, we wish to count how many ways are there of creating $r$ ordered samples?   We can easily do both with and without replacement.

\begin{itemize}
\item[(i)] with replacement: $n^r$ (this is the fundamental theorem of counting)
\item[(ii)] without replacement $n(n-1)(n-2)\ldots(n-r+1)$,  calculation reduces to: $\frac{n!}{(n-r)!}$ 
\end{itemize}

\begin{eqnarray*}
&=& n(n-1)(n-2)\ldots(n-r+1) \\
&=& \frac{ {\color{red} n(n-1)(n-2)\ldots(n-r+1)} {\color{blue} (n-r)(n-r-1)(n-r-2)\ldots(1)}}{{\color{blue} (n-r)(n-r-1)(n-r-2)\ldots(1)}} \\
&=& \frac{n!}{(n-r)!}
\end{eqnarray*}

%(that's probably a dumb way of calculating it, but a very neat way of writing it)

Note, if we want to know all possible ways of arranging $n$ items we just need $n!$ - $0! = 1$

 

 

\section{Combinations}

\subsection{Unordered sets}

Two sets are regarded as disjoint if and only if the properties of the membership are mutually exclusive.   
A \emph{partition} is defined as a set of disjoint and exhaustive subclasses of a given class that is divided in such a way that each member of the given class is a member of exactly one such subclass.

 

\subsection{Without replacement}

The number of ways a set of $n$ objects can be partitioned into 2 distinct subsets of size $r$ and $n-r$ is given by:

\begin{equation}
{n \choose r} = \frac{n!}{r!(n-r)!}
\end{equation}

(This is what Baclawski calls the Shepherd principle.   If you get tired counting sheep, count the legs and divide by four.   We saw above that there were $\frac{n!}{(n-r)!}$ different ordered sets, we need to divide by the $r!$ different ordering of each combination)

\subsubsection{Important shorthand: $n$ choose $r$}

This is such an important idea that it has it's own shorthand:

\begin{displaymath}
\frac{n!}{r!(n-r)!} = \binom{n}{r}
\end{displaymath}

 



\subsubsection{Side issue 1: Partitioning into k-subsets}

The number of ways a set of $n$ objects can be partitioned into $k$ distinct subsets, where set 1 has $r_1$ elements, set 2 has $r_2$ elements, \ldots, set $k$ has $_k$ elements is:

\begin{equation}
\frac{n!}{r_1!r_2! \ldots r_k!}
\end{equation}




%\subsection{Permutations and combinations}

%Consider the probability of getting two of a kind and three of a kind when rolling five dice e.g., $(2,2,5,5,5)$ or $(4,4,1,1,1)$.   If we denote the number on the $i$th die by $n_i$, we have a sample space that consists of all the ordered 5-tuples ($n_1, n_2, n_3, n_4, n_5$) we have $n(\Omega)=6^5$.   Now introduce an ordered pair $(i,j)$ where $i$ is the number appearing twice, and $j$ the number that appears three times.  There are $\frac{6!}{(6-2)!}$ ways of obtaining 



 
\subsubsection{Side issue 2: Pascal's Triangle}

It's not worth losing sleep over, but it's impossible at this stage not to mention Pascal's\footnote{apparently discovered by Jia Xian in 1050, published by Zhu Shije in 1303, discussed by Cardano in 1570} triangle:

\begin{footnotesize}
\begin{tabular}{rrrrrrrrrrrrrrr}
 & &  &  &  &  &  &1 &  &  &  &  & &\\
 & &  &  &  &  & 1&  &1 &  &  &  & &\\
 & &  &  &  & 1&  &2 &  & 1&  &  & &\\
 & &  &  & 1&  &3 &  &3 &  &1 &  & &\\
 & &  & 1&  &4 &  &6 &  &4 &  &1 & &\\
 & &1 &  & 5&  &10&  &10&  & 5&  &1& \\
 &1&  &6 &  &15&  &20&  &15&  & 6& & 1\\
1& & 7&  &21&  &35&  &35&  &21&  &7&1
\end{tabular}
\end{footnotesize}

Note that each number in the triangle is the sum of the two numbers either side of it in the row above.   Now consider you have a pool of $7$ objects, and wish to know how many different ways there are of arranging them into sets of $3$.   We used above ${n \choose r} = {7 \choose 3} =  \frac{7!}{3!(7-3)!} = 35$.   However, if we number the rows of Pascal's triangle from 0 (at the top) to 7, take row 7 and count along to the 4th entry, we have 35.   Isn't that cute?


 

\subsection{Combinations: Undordered with replacement}

To keep this simple let's roll a die three time, and work out something like the probability of getting two faces showing $3$ and one showing $6$.   Let's illustrate the idea as:

\begin{tabular}{lr|r|r|r|r|r}
Face & 1 & 2 & 3 & 4 & 5 & 6\\
Hits &   &   &Y Y&   &   & Y
\end{tabular}

Note how this reduces to a problems of bins and walls such that we can specify this particular arrangement as:

$||YY|||Y$

Note we have walls between $1$ and $2$, between $2$ and $3$, then two entries in the bin marked $3$.   This problem is therefore equivalent to finding an ordered arrangement of $n$ items and $k-1$ walls hence the number of combinations is given by:

\begin{displaymath}
\binom{n+r-1}{r}
\end{displaymath}



 


\subsection{A word problem}

Just to convince you that these problems don't just consist of finding the right formulae from the four given above, here is related idea (which you can easily solve if you think a little).   Consider the manager of a small plant wishes to determine the number of ways which he can assign staff to the first shift.   There are $15$ staff who can serve as operators of the production equipment, $8$ who can serve as maintenance personnel and $4$ who can be supervisors.

If a shift requires one operator, one maintenance person and one supervisor, how many different ways can the shift the staffed?    The answer is $480$, which is rather tedious if one had to draw the tree diagram, and doesn't quite fit the formulae above, although the principles set out there do apply.

 

 

%\subsection{Side issue: Bose Einstein}

%Imagine tossing two coins, but the coins have three faces (H, T, S).   If you were asked for the sample space of such an experiment you might say there are 9 events in the sample space.

%\begin{itemize}
%\item[] $H_1, H_2$
%%\item[] $T_1, T_2$
%\item[] $S_1, S_2$
%\item[] $H_1, T_2$ and $T_1, H_2$ 
%\item[] $H_1, S_2$ and $S_1, H_2$ 
%\item[] $T_1, S_2$ and $S_1, T_2$
%\end{itemize}

%By the naive definition, we have $P(\mbox{One head, one tail})=\frac{2}{9}$.
% 

%Very roughly speaking, you could imagine a simple gas made up of two particles (two coins), each of which can take on one of three quantum states (here $H$, $T$ or $S$).   As I understand it, this situation above roughly corresponds to Maxwell-Boltzmann statistics.   The fascinating thing is that under Bose-Einstein statistics, the particles (coins) are indistinguishable, and under Bose-Einstein you might say we would have a sample space:
% 

%\begin{itemize}
%\item[] $H,H$
%%\item[] $T,T$
%\item[] $S,S$
%\item[] $H,T$
%\item[] $H,S$
%\item[] $T,S$
%\end{itemize}

%and if this were indeed a sample space then $P(\mbox{One head, one tail})=\frac{1}{6}$.   This seems to trash 100 years of mediaeval work on the enumeration of sample spaces.   Neverthless, Bose-Einstein did rather a lot more work and predicted a ``condensate'' which was discovered experimentally 70 years after their theoretical work.


%You can rest assured that there will be no exam questions on Bose-Einstein.   The reason for mentioning this is really to highlight the importance of probability within quantum physics, and to admit that physicists develop the basic idea in a very different direction to statisticians.


\section{Circular permutations}

To be honest I've not seen a huge need for this in undergraduate statistics.   It is an important topic in other branches of mathematics.  As this is a probability course and you have all signed up to study either BSc Mathematics or BSc Mathematics with something, we're going to do some work on this topic.

The key idea is one of redundancy.   

\subsection{Clockwise and anti-clockwise order matters (tables)}

\begin{minipage}[t]{.45\textwidth}
\textbf{Dinner party 1}
\begin{tikzpicture}

\def \n {4}
\def \radius {3cm}
\def \margin {8} % margin in angles, depends on the radius

\foreach \s in {1,...,\n}
{
\SUBTRACT{\s}{1}\a
  \node[draw, circle] at ({360/\n * (\s - 1)}:\radius) {$\a$};
  \draw[-, >=latex] ({360/\n * (\s - 1)+\margin}:\radius) 
    arc ({360/\n * (\s - 1)+\margin}:{360/\n * (\s)-\margin}:\radius);
}
\end{tikzpicture}
\end{minipage}%
\begin{minipage}[t]{.45\textwidth}
\textbf{Dinner party 2}
\begin{tikzpicture}

\def \n {4}
\def \radius {3cm}
\def \margin {8} % margin in angles, depends on the radius

\foreach \s in {1,...,\n}
{
\ADD{\s}{1}\a
\INTEGERDIVISION{\a}{4}{\zzz}{\b}
  \node[draw, circle] at ({360/\n * (\s - 1)}:\radius) {$\b$};
  \draw[-, >=latex] ({360/\n * (\s - 1)+\margin}:\radius) 
    arc ({360/\n * (\s - 1)+\margin}:{360/\n * (\s)-\margin}:\radius);
}
\end{tikzpicture}
\end{minipage}

If we moved the table by 180 degrees (assuming the chairs are fixed to the table) both settings are identical.



Hence, we can find the number of permutations using $(n-1)!$

\subsection{Clockwise and anti-clockwise doesn't matter (necklaces)}

We can look from the top or the bottom, in other words we need to apply the shepherd principle.

\begin{tikzpicture}

\def \n {4}
\def \radius {3cm}
\def \margin {8} % margin in angles, depends on the radius

\foreach \s in {1,...,\n}
{
\MULTIPLY{\s}{-1}\a
\ADD{\a}{4}\b
  \node[draw, circle] at ({360/\n * (\s - 1)}:\radius) {$\b$};
  \draw[-, >=latex] ({360/\n * (\s - 1)+\margin}:\radius) 
    arc ({360/\n * (\s - 1)+\margin}:{360/\n * (\s)-\margin}:\radius);
}
\end{tikzpicture}

Is this equivalent to the previous representation?

$\frac{(n-1)!}{2!}$


\subsection{Fusions}

The Tony Blair problem.


\chapter{A non-naive definition of probability}


\section{The Axioms of Probability}

The system of probability we have been working through took a long time to develop, and wasn't fully formalised until the 1930's by Kolmogorov (see 
\href{http://www.gap-system.org/~history/Biographies/Kolmogorov.html}{\color{blue}www.gap-system.org/~history/Biographies/Kolmogorov.html}).   He stated three fundamental Axioms, from which all other results can be derived.


\section{Axioms of probability}

\fbox{
  \begin{minipage}[c]{1.0\linewidth}
\begin{itemize}
\item $p[A] \geq 0$ for any event $A$
\item $p[\Omega] = 1$ where $\Omega$ is the sample space 
\item If $[A_i];i=1,2,\ldots$ are mutually exclusive then $p[A_1] \cup p[A_2] \cup \ldots = p[A_1] + p[A_2] + \ldots$
\end{itemize}
\end{minipage}
}

Mutually exclusive means that $A_i \cap A_j = \emptyset$ for all $i \neq j$


We shall examine the implications of these Axioms in terms of obtaining mathematical functions that can serve as models for probability (probability distribution functions) in week 2.   The intuitive consequences of these results are:

\begin{itemize}
\item (Non-negative) Probability can never be negative
\item (Total probability) The probability of a sample space must equal 1 
\item (Countable additivity) The probability of observing two (or more) mutually exclusive events is the sum of their individual probabilities
\end{itemize}

However, we need to derive some additional results from these Axioms in order to be able to carry out useful probability calculations.



\subsection{Deriving $P(A^C)$}

The sets $A$ and $A^C$ form a partition of the sample space so that $\Omega = A \cup A^C$.   We therefore know by the second axiom that $P(A \cup A^C) = 1$.   By the third axiom we know that $P(A \cup A^C) = P(A) + P(A^C)$ so we can rearrange this to give:

\begin{align*}
P(A \cup A^C) &= P(A) + P(A^C) \\
P(A \cup A^C) - P(A) &= P(A^C) \\
P(A^C) &= 1 - P(A)
\end{align*}

\subsection{Deriving $P(A) \leq 1$}

If $P(A^C) \geq 0$ and $P(A) + P(A^C) = 1$ this is immediate.

\subsection{Deriving the addition rule}

Consider the set $B$, which we can expand as $B=(B \cap A) \cup (B \cap A^C)$.   This tells us (eventually) that

\begin{displaymath}
P(B) = P(B \cap A) + P(B \cap A^C)
\end{displaymath}
Note that the two terms on the right hand side are disjoint so we can use the third axiom.

Now we want to think about $A \cup B = A \cup (B \cap A^C)$, again the two terms on the right hand side are mutually exclusive/disjoint.   

\begin{align*}
P(A \cup B) &= P(A) + P(B \cap A^C) \\
 &= P(A) + P(B) - P(A \cap B)
 \end{align*}



You can verify this; draw the Venn Diagram.   If we merely added $p[A]$ to $p[B]$ for events with an intersection, we would add the probability corresponding to $p[A \cap B]$ twice, and hence we need to subtract one of these areas.

{\color{green}What does this tell us about the value of $p[A \cap B]$ for for mutually exclusive events?}


\section{Problems}
\begin{enumerate}
\input{Problems/dummy1/Set1_AdditionRuleProof.tex}
\input{Problems/dummy1/Set1_AdditionRule.tex}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%
%%%%%%% CONDITIONAL PROBABILITY
%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conditional Probability}

Actually, all probability is conditional, it just gets tedious to write $P(X|\Omega)$.   The key to using probability correctly is to condition correctly.   
We wish to find out how we update probability (or belief!!!!) in the presence of additional information.

\begin{itemize}
\item To examine conditional probability
\item To define the term ``independence'' a little more precisely
\item To state Bayes Theorem
\end{itemize}


% 


 

\section{Conditional probability - why the fuss}

For full details of these problems see Leonard Mlodnikov ``A drunkard's walk'', a lovely popular science book.

\begin{itemize}
\item Make the simplifying assumption that $p(\mbox{Baby is boy}) = 0.5$ and $p(\mbox{Baby is girl=0.5})$.
\item Consider a two child family.   You know that one child is a girl.   What is the probability that the other child is a girl?
\item Consider a two child family.   You know that one child is a girl called Mirabehn.   What is the probability that the other child is a girl
\end{itemize}

For a more formal, exam relevant coverage of this material see Chapter 4 in Blitzstein and Hwang

 

\subsection{Solution 1}

Hopefully you gave the na\"ive answer $0.5$.   Now consider the (also slightly na\"ive) take on the sample space for a two child family which consists of:

\begin{tabular}{r}
BB \\
{\color{red}BG} \\
{\color{red}GB}\\
{\color{red}GG}
\end{tabular}

So hopefully you see the ``correct'' answer is $\frac{2}{3}$, as we should condition on the three events where a family has a girl.

 

\subsection{Solution 2}

Here I simplify a little, and don't explain some of the simplifications in these notes (ask me or see Mlodnikov).   Denote $G_M$: a girl called Mirabehn and $G_N$ and girl not called Mirabehn.

\begin{tabular}{rr}
$G_N$ $G_M$ &  \\
$G_M$ $G_N$ &  \\
$G_M$ $B$   & $G_N$ $B$ \\
$B$ $G_M$  & $B$ $G_N$ \\
$G_M$ $G_M$ & $G_N$ $G_N$\\
 & $B$ $B$ \\
\end{tabular}

(As it stands, that is no equal probability sample space, but by choosing a rare name when we choose only those events featuring $G_M$ we get some closeness to four events of similar probability - assuming we can discard the possibility of two girls of the same name).   

Note when we condition on $G_M$ we get four events, two of which feature a second girl so the probability is (approximately) $\frac{1}{2}$

  

\subsection{Conditional probability defined}

Hopefully, that little exercise has convinced you conditional probability is a topic where you need to be fully alert!   Most of the fun comes from carefully specifying and identifying the event on which you are conditioning.   But it's not all nuisance, being able to condition also helps us solve many problems.


To date, we have only considered information obtained from:


\begin{itemize}
\item[(a)] Specifying the sample space and
\item[(b)] explicitly or implicitly (or na\"ively) specifying a probability measure on that sample space
\end{itemize}

However, knowledge that a particular event has taken place can alter our assessment of the probability of other events.   Consider a student who wishes to pass his course.   However, this student doesn't like attending lectures.   he is told that his chances of passing the course will increase if he attends lectures.

We can write this \emph{conditional probability} as:
\begin{displaymath}
p[\mbox{Student will pass course} | \mbox{Student attends lectures}]
\end{displaymath}

 

You have previously examined the situation where we could examine $A$ (the event that the student attends lectures, the circle on the left), $B$ (the event that the student passes, the circle on the right) as well as the intersection.   We could draw a Venn diagram something like the one below:


\def\firstcircle{(0,0) circle (1.5cm)}
\def\secondcircle{(0:2cm) circle (1.5cm)}

\colorlet{circle edge}{blue!50}
\colorlet{circle area}{blue!20}

\tikzset{filled/.style={fill=circle area, draw=circle edge, thick},
    outline/.style={draw=circle edge, thick}}

\setlength{\parskip}{5mm}
% Set A and B
\begin{tikzpicture}
\begin{scope}
        \clip \secondcircle;
        \draw[filled, even odd rule] \firstcircle
                                     \secondcircle node {$B$};
    \end{scope}
    \draw[outline] \firstcircle node {$A$}
                   \secondcircle;
    \node[anchor=south] at (current bounding box.north) {$B - A$};
\end{tikzpicture}    


%\includegraphics[width = 0.3\textwidth]{venn1}


However, once we know that the student has indeed attended lectures, the information we have on the problem changes the question.   We are no longer interested in $A^C$, as we know the student attended.   Hence, we {\color{green}\emph{condition}} our interest on $A$

\begin{tiny}
Please ignore the fact that this diagram seems to show rather a lot of probability associated with the event that the student passes when he doesn't attend lectures - this is only a simple illustration;-)
\end{tiny}

 

A reduced diagram would look like the following.   We therefore want to know the probability of the student passing, given that we know he attended lectures.

%\includegraphics[width = 0.3\textwidth]{venns}


We can use the following statement:

\begin{df}
\begin{displaymath}
p[A|B] = \frac{p[A \cap B] }{p[B]} \mbox{ if } p[B] > 0
\end{displaymath}
\end{df}
to solve this problem.   This expression is undefined if $p[B] = 0$

 

In frequency terms, this expression can be thought of as:

\begin{displaymath}
\frac{\mbox{Number of experiments in which both A and B occurred}}{\mbox{Number of experiments in which B occurred}}
\end{displaymath}


Strictly speaking, all probability is conditional.   Earlier in the course we could have referred to $p(A)$ as $p(A|\Omega)$.


 


 

\subsection{Axioms of conditional probability}

As with probability, we only need a few axioms for conditional probability.   
%(See Amemiya, 1994, page 10, who provides the argument that you only need one axiom from which the others can be drawn)

\begin{df}Axioms of conditional probability:

\begin{itemize}
\item $p[A|B] \geq 0$ for any event $A$
\item $p[A|B] \leq 1$ for any event $A \supset B$
\item If $A_1, A_2, \ldots$ is a sequence of mutually exclusive events then: $p[A_1 \cup A_2 \cup \ldots | B] = p[A_1|B] + p[A_2|B] + \ldots$
\item If $A_1 \supset B$ and $A_2 \supset B$ and $p[B] \neq 0$ then $\frac{p[A_1|B]}{p[A_2|B]} = \frac{p[A_1]}{p[A_2]}$
\end{itemize}

\end{df}

It can be seen that conditional axioms (1), (2) and (3) are analogous to the axioms of probability.   The fourth axiom tells us that the relative frequency $A_1$ versus $A_2$ remains the same after $B$ has happened. 

 
\subsection{Consequences}

A few small points worth mentioning:

\begin{itemize}
\item $p[B|B] = 1$
\item $p[A^C|B] = 1 - p[A|B]$
\item $p[A_1 \cup A_2 | B] = p[A_1|B] + p[A_2|B] - p[A_1 \cap A_2 | B]$
\end{itemize}

But let's really have some fun with our main definition:



%But we have an additional theorem that is specific to conditional probability and quite useful:
%\begin{df}
%For any pair of events $A$ and $B$, where $p[B] > 0$:
\begin{displaymath}
p[A|B] = \frac{p[A \cap B]}{p[B]}
\end{displaymath}
%\end{df}


 

Let's start by multiplying both sides by $p(B)$

\begin{displaymath}
p[A|B]p[B] = p[A \cap B]
\end{displaymath}

Now let's note that the labels $A$ and $B$ are arbitrary.   So it must also be true that
\begin{displaymath}
p[A \cap B] = p[B|A]p[A]
\end{displaymath}

In other words we have shown that

\begin{displaymath}
p[A|B]p[B] =  p[B|A]p[A]
\end{displaymath}
and if I divide both sides by $p[B]$ I have just proved Bayes' Theorem (which we define more carefully later).
%\begin{df}
\begin{displaymath}
p[A|B] = \frac{p[B|A]p[A]}{p[B]}
\end{displaymath}

 

We need to say more about that $p[B]$ denominator, but first let's illustrate the key idea with natural frequencies.   Consider a dread disease, and consider that $1$ person in $10,000$ has this disease.   Now consider a screening test for that disease, if you have the disease, it will detect it with probability $0.95$.   If you don't have it, it will give you the all clear with probability $0.9$.   

Now imagine you have gone to your physician, done the test, and been told you have the disease.   Should you be worried?

 

First time round, let's consider this problem with natural frequencies.   Let's invent a population as follows:

\begin{tabular}{rrrr}
 & Disease & No disease & Total \\
Test positive \phantom{95} & \phantom{99,990} & \phantom{100,085} \\
Test negative \phantom{5} & \phantom{899,910} & \phantom{899,915} \\
Total & 100 & 999,900 & 1,000,000
\end{tabular}

So, as you can see, with $1$ in $10,000$ having the disease, our ficitional population of $1,000,000$ has $100$ cases with the remainder being non-cases.

 

Now, we were told that if you have the disease (if you are one of the $100$ people), the test will detect it $0.95$ of the time.   So let's fill in these numbers:

\begin{tabular}{rrrr}
 & Disease & No disease & Total \\
Test positive 95 & \phantom{99,990} & \phantom{100,085} \\
Test negative 5 & \phantom{899,910} & \phantom{899,915} \\
Total & 100 & 999,900 & 1,000,000
\end{tabular}

So, as you can see, with $1$ in $10,000$ having the disease, our ficitional population of $1,000,000$ has $100$ cases with the remainder being non-cases.

The next step will be to do the same for the people who don't have the disease:


 

It's becoming obvious I think where this is going.   Look at the effect of adding $0.1$ of the disease free individuals to the row that test positive.  So we've leapt into adding the row totals.

\begin{tabular}{rrrr}
 & Disease & No disease & Total \\
Test positive 95 & 99,990 & 100,085 \\
Test negative 5 & 899,910 & 899,915 \\
Total & 100 & 999,900 & 1,000,000
\end{tabular}


So now, if I want the probability that I have the disease, given I tested positive, it is $\frac{95}{100,085}$ which is about $0.000949$.    Not much to worry about really!!!

Hopefully this explains the concept (Psychologists sometimes call this Baseline Bias), but we want to be a little more mathematical in our approach.



\subsection{Law of alternatives}

The only problem with the derivation given is that I've been a bit glib about where $p[B]$ came from.   Now we only know that one of several possible events $A_1$,$A_2$, $\ldots$ has occured (there may be infinitely many of these alternatives).

If
\begin{itemize}
\item $A_i$ $i \geq 1$ are pairwise disjoint
\item $p(\bigcup_i A_i)=1$ (we sometimes require the condition that $\bigcup_i A_i = \Omega$
\item $p(A_i)>0$ for every $i$
\end{itemize}
then
\begin{displaymath}
p(B)=p(B|A_1)P(A_1) + p(B|A_2)p(A_2) + \cdots
\end{displaymath}



 
\subsection{Bayes Theorem}

This is rather an important theorem, and follows from the above.   As stated here, this theorem is a well accepted argument.

\begin{df}
Let events $A_1, A_2, \ldots, A_n$ be mutually exclusive, such that $p[A_1 \cup A_2 \cup \ldots \cup A_n] = 1$ and $p[A_i] > 0$ for each $i$.   Let $B$ be an event such that $p[B] > 0$.  Then:

\begin{displaymath}
p[A_i | B] = \frac{p[B|A_i]p[A_i]}{\sum_{j=1}^n p[B|A_j]p[A_j]}, i=1,2,\ldots, n
\end{displaymath}
\end{df}

 

As stated, Bayes theorem is a very simple and widely accepted result in conditional probability.   Occasionally we use the following terminology:

\begin{itemize}
\item Prior probability: $p[A_i]$
\item Posterior probability $p[A_i | B]$
\end{itemize}


Where Bayes theorem starts to get interesting is when we no longer use simple probabilities in the calculations.  Specifically, when we start using the likelihood as $p[B|A_i]$ we can carry out some very interesting inference.



\chapter{Discrete Probability Functions}

\chapter{Expectation}

\chapter{Continuous Probability Functions}
\chapter{Moments}

\end{document}
