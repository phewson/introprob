\documentclass[12pt]{extbook}
\title{Probability with Applications: Course Notes}
\author{Paul Hewson and Malgorzata Wojtys}
\date{February - May 2016}
\usepackage{amsmath,amssymb,amsfonts,graphics,hyperref,color,setspace,synttree,keystroke}
\usepackage{calculator}
\usepackage{longtable}
\everymath{\displaystyle}
\usepackage{longtable}
\usepackage{a4wide,color,Sweave,url,verbatim,xargs,longtable}
\usepackage{tikz}
\newenvironment{question}{\item \textbf{Problem}\newline}{}
\newenvironment{solution}{\comment}{\endcomment}
\newenvironment{answerlist}{\renewcommand{\labelenumi}{(\alph{enumi})}\begin{enumerate}}{\end{enumerate}}
\newtheorem{df}{Definition}[section]
\newtheorem{tm}{Theorem}[section]
\begin{document}
\sffamily
\onehalfspacing

\maketitle

\chapter{Background to the course and course administration}

\section{How you will be assessed}

\begin{itemize}
\item 2 hour Exam (70\%)
\item Coursework (30\%)
\end{itemize}

The coursework will consist of a mixture of exam type questions which you can complete electronically on Moodle as well as a small activity that you have to write up and also submit to Moodle.

\section{How you pass the assessment}

We set a lot of problems, which you should attempt.   You will be given chances in computer labs to attempt some problems where you can ask for clarification if needs be.   The problems we do in class are the same kind of problems as you get on the exam.

\section{Why study probability?}

There is a perception (often gained by taking A level modules) that probability is statistics.   Please don't confuse the two.   Statistics is a process of drawing inference about a population from a sample of data, and yes, it uses many techniques from various branches of mathematics including probability.   But probability is a mathematical field in its own right, the logic of uncertainty.   There are various reasons for studying probability:

\begin{itemize}
\item In order to gain a mature mathematical understanding of statistical inference
\item In order to understand physics (and particularly quantum physics)
\item In order to develop various computer science algorithms, such as the so-called Monte Carlo methods
\item In order to understand gambling and finance (I believe these are separate topics, but there are lucrative careers to be made as an actuary)
\item Applied probability in its own right
\end{itemize}

This module is intended as a formal introduction to the branch of mathematics known as probabilty.   We will illustrate applied probability where possible to keep the module alive.   It is \emph{not} a course in statistics.   Discrete probability allows you to use some very simple arithmetic to solve some very baffling problems and is a good way of developing rigorous mathematical reasoning skills.   Probability generally touches on several branches of mathematics and this course will give you the opportunity to practice your skills in areas such as calculus.

\section{Background Definitions}

There is a fascinating philosophical / linguistic / epistemological history behind the concept of probability.   For our purposes, \emph{Probability} is nothing more than a number between $0$ and $1$ that behaves in accordance with three axioms.   However, you can do a lot with numbers.   You can think of probability as being:

\begin{itemize}
\item A symmetrical thing (the coin has two faces, heads and tails)
\item A long run frequency thing (out of 10,000 coin tosses, 5,023 were heads)
\item A subjective thing (that person is obvious a crook and if they want me to bet on tails it is very likely they have a rigged coin)
\end{itemize}


%%%%%%%%%%%%
%%%%%%%%%%%% Need to add a timetable here I think
%%%%%%%%%%%%





\chapter{Brief review of Sets}

A set is a collection of distinct objects.   We need to be a little careful here.   A set can be finite or infinite.   The objects can be real or abstract.   But they have to be distinct.   So the digits $(1,4,3,4)$ do not form a set because there are two number $4$s.   However an urn full of blue balls is a set because in principle we could number the balls and hence they are all distinct.

We can define sets in various ways, such as 

\begin{itemize}
\item By listing the numbers $A=\{1,3,5,7\}$
\item By stating a rule $B=\{ x:0 < x < 1\}$
\end{itemize}


To indicate that an object $x$ is an element of a set we write $x \in A$.

(In case we need it, we talk about the empty set $\emptyset$ (the set which has no elements) and the cardinality of a set $|A|$ as the number of elements of a set.)


Here are a few celebrity sets:

\begin{itemize}
\item $\mathbb{P}$ for prime numbers
%\mathbb{W} for whole numbers using \mathbb{W},
\item $\mathbb{N}$ natural numbers ,
\item $\mathbb{Z}$ integers 
%\mathbb{I} for irrational numbers using \mathbb{I},
%\mathbb{Q} for rational numbers using \mathbb{Q},
\item $\mathbb{R}$  real numbers
%\mathbb{C} for complex numbers using \mathbb{C}.
\end{itemize}


\section{Functions}

We will need to be familiar with a couple of key ideas around functions.   These are utterly fundamental to mathematics and you will know all this already.   But it's set out here for completeness.   A function $f: A \to B$ between sets $A$ and $B$ assigns to each $x \in A$ a unique element $f(x) \in B$.   

\begin{itemize}
\item We call the set $A$ on which $f$ is defined the domain
\item We call the set $Y$ on which $f(x)$ takes its values the co-domain
\item The range, or image, of a function $f : A \to B$ is the set of values 
\begin{displaymath}
\mbox{range} f= \left\{ y \in B : y=f(x) \mbox{ for some } x \in A \right\}
\end{displaymath}
\end{itemize}

\begin{itemize}
\item The identity function $id$ matches every element of $A$ onto itself
\item Let $B \subset A$.   The indicator function $I$ of $B$  can be defined such that

\begin{displaymath}
I(x) = \left\{ \begin{array}{rrr} 1 && \mbox{ if } x \in B \\
0 & & \mbox{ if } x \notin B \end{array} \right.
\end{displaymath}

\item The square function $f : \mathbb{N} \to \mathbb{N}^2$ is defined as $f(n) = n^2$.   Now, notice that we have problems.   Although  $g(n) = \sqrt(n)$ defines a function $g : \mathbb{N} \to \mathbb{R}$ we would have problems with $h(n) = \pm \sqrt{ n}$ because it does not define a unique value for $h(n)$.
\end{itemize}

There are a few more fundmentals, such as onto (surjection) one-to-one (injection) and both (bijection) as well as composition.   These might not be essential for this module.   We do however need to watch domains very carefully throughout this course!

%\subsubsection{Set theory notation}

% I might not cover this in a lecture, we need the first six rows at the moment, the rest are only needed if we were going to do a lot of proofs and some very formal probability theory.
 
% For completeness, we quote a table from Grimmett and Stirzaker (2004) which gives a listing of set theory and probability theory notation.\\[0.5in]

% {\color{blue}
% \begin{footnotesize}
% \begin{tabular}{lll}
% Notation & Set theory & Probability Theory \\
% \hline
% $\Omega$ & A collection of objects & Sample space \\
% $\omega$ & A subset of $\Omega$ & Elementary event/outcome\\
% $A$ & A subset of $\Omega$ & Event that some condition $A$ occurs \\
% $A^C$ & Complement of $A$ & No event $A$ occurs \\
% $A \cap B$ & Intersection of $A$ and $B$ & Both $A$ and $B$ occur \\
% $A \cup B$ & Union of $A$ and $B$ & Either $A$ occurs, or $B$ occurs or both
% \\
% $A \setminus B$ & Difference & $A$ occurs but $B$ does not occur \\
% $ A \bigtriangleup B $ & Symmetric difference & Either A or B but not both \\
% $A \subseteq B$ & Inclusion & If $A$ occurs then $B$ occurs \\
% $\emptyset$ & Empty set & Impossible event \\
% $\Omega$ & Whole space & Certain event
% \end{tabular}
% \end{footnotesize}
% }


\section{Sample spaces: how we use Sets}

\textit{More information is given in Section 1.2 of Blitzstein and Hwang}

Here are some key definitions:

\fbox{
  \begin{minipage}[c]{1.0\linewidth}
An \emph{experiment} %(esperimento) 
is any process that generates a set of outcomes where the outcome is uncertain.   For a random experiment:

\begin{itemize}
\item The \emph{sample space} $\Omega$ is the set of all possible outcomes 
%(campione di spazio)
\item An \emph{event} is a subset of the sample space 
%(evento)
  \begin{itemize}
  \item A \emph{simple event} is an event which cannot be a union of other events
  \item A \emph{composite event} is an event which is not a simple event
  \end{itemize}
\item The \emph{event space} is the set of all events (evento di spazio)
\end{itemize}
\end{minipage}
}

\subsection{Example}

Consider an experiment in which three coins are tossed.   We are interested in the {\color{red}\emph{event}} that all coins will show the same face. 



The following tree diagram denotes the breakdown of the sample space ($\Omega$).   After the first coin toss we have either a head or a tail.   After the second, for either of the possible outcomes of the first toss we also have a head or tail.   Finally, after the third coin toss, we have a row denoting that a head or tail is possible for any of the previous outcomes. 

%% Cardano was the first person to start thinking about systematically evaluating sample spaces in this way, but he missed a trick in that to him HTH and HHT would be the same (two heads and a tail).   It took nearly 100 years and Galileo to really master the business of sample spaces.  


\subsection{Tree diagram}

\begin{figure}[!h]
\synttree[$\Omega$ [H [H [H][T]][T [H][T]]]  [T [H [H][T]][T [H][T]]]] 
\end{figure}


In total therefore, the tree diagram shows on the bottom row that there are a total of $2^3$ possible outcomes in the sample space.   In other words, there are 8 different ways of travelling though the tree diagram,  resulting in the following outcomes: 
\begin{itemize}
\item {\color{red}HHH}, HHT, HTH, HTT, THH, THT, TTH, {\color{red}TTT}.
\end{itemize}  



 We are interested in the event that all faces are the same.   There are two outcomes in the sample space which correspond to this event - denoted in red.\\[0.25in]   

\fbox{
\begin{minipage}[c]{3.5in}
Recap:
\begin{itemize}
\item {\color{blue}Sample Space} ($\Omega$) - the eight outcomes for the experiment: 
\\{\color{red}HHH}, HHT, HTH, HTT, THH, THT, TTH, {\color{red}TTT}. 
\item {\color{blue}Event} ($A$) - the two outcomes of interest: {\color{red}HHH}, {\color{red}TTT}
\end{itemize}
\end{minipage}
}
\vspace{0.25in}

There are 8 outcomes in our sample space, two of them correspond to the event ``all three coins show the same space''.   If we continue to focus on naive definitions of probability, it pays us to consider Venn diagrams.


% We can form collections $\mathfrak{B}$ of (overlapping or non-overlapping) subsets of our sample space $\Omega$.   There are some restrictions on these collections which must be:

% \begin{itemize}
% \item The empty set $\emptyset$ must be in the collection $\mathfrak{B}$
% \item If $A \in \mathfrak{B}$ then $A^C \in \mathfrak{B}$
% \item If $A_1, A_2, \ldots \in \mathfrak{B}$ then $\cup_{i=1}^\infty A_i \in \mathfrak{B}$
% \end{itemize}

% These might seem trivially obvious for the naive problems, and hopefully we won't need to say any more.   For example, the second condition tells you if you have a world cup final of Argentina versus Germany, you can't say the complement of Argentina winning is Brasil winning however happy Brasilian fans might be with a German victory.


\subsection{Venn diagram}

An alternative method of visualising is via a Venn Diagram.

\begin{center}
\begin{figure}[!h]
\begin{picture}(200,110)
\put(0,0){\framebox(200,110){}}
\qbezier(15,55)(15,105)(65,105)
\qbezier(65,105)(115,105)(115,55)
\qbezier(115,55)(115,5)(65,5)
\qbezier(65,5)(15,5)(15,55)

%\qbezier(80,55)(80,105)(130,105)
%\qbezier(130,105)(180,105)(180,55)
%\qbezier(180,55)(180,5)(130,5)
%\qbezier(130,5)(80,5)(80,55)
\put(5,95){$\Omega$}
\put(40,50){$A$ (HHH, TTT)}
\put(130,50){$A^C$ }
\put(120,30){ (HTH HTH HHT }
\put(120,10){ THT TTH THH)}
%\put(80,50){ $A \cap B$}
\end{picture}
\end{figure}
\end{center}


In this diagram, $A$ denotes the event ``all three faces show the same'', and $A^C$ denotes ``A complement'' (also known as ``not A''), in other words the six outcomes where the faces are not identical.  




\subsection{Multiple events}


\fbox{
\begin{minipage}[c]{1.0\textwidth}
\textbf{Notation}
\begin{itemize}
\item $\cup$ denotes the ``union'' of two sets, e.g., $A \cup B$ is the event that either $A$ occurred, or $B$ occurred or both occurred
\item $\cap$ denotes the ``intersection'' of two sets, e.g. $A \cap B$ is the event that both $A$ and $B$ occurred
\item ``Mutually exclusive"" means that either $A$ can happen, or $B$ but not both
\end{itemize}
\end{minipage}
}

For the same experiment, consider again the event $A$, ``all three coins show the same face''.   But now, consider a second event, $B$, which we define as ``two or more coins show a head''

\begin{itemize}
\item A: {\color{red}HHH}, HHT, HTH, HTT, THH, THT, TTH, {\color{red}TTT}.
\item B: {\color{blue}HHH}, {\color{blue}HHT}, {\color{blue}HTH}, HTT, {\color{blue}THH}, THT, TTH, TTT
\end{itemize}

As before, 2 out the 8 outcomes correspond to event $A$.   We can also see that 4 of the 8 outcomes correspond to event $B$.   We can also see that one outcome (HHH) corresponds to both event $A$ and event $B$.   We can extend the Venn diagram to illustrate this:


\begin{center}
\begin{figure}[!h]
\begin{picture}(200,110)
\put(0,0){\framebox(200,110){}}
\qbezier(15,55)(15,105)(65,105)
\qbezier(65,105)(115,105)(115,55)
\qbezier(115,55)(115,5)(65,5)
\qbezier(65,5)(15,5)(15,55)

\qbezier(80,55)(80,105)(130,105)
\qbezier(130,105)(180,105)(180,55)
\qbezier(180,55)(180,5)(130,5)
\qbezier(130,5)(80,5)(80,55)
\put(5,95){$\Omega$}
\put(40,50){A}
\put(35,35){(TTT)}
\put(130,50){B}
\put(125,35){(THH HTH}
\put(125,20){ HHT)}
\put(80,50){ $A \cap B$}
\put(80,35){ (HHH)}
\end{picture}
\end{figure}
\end{center}



You can see that we use the Venn diagram to visually illustrate that the outcome HHH is in both event A and event B.   Standard set theory notation $A \cap B$ is used to denote that this is an ``intersection''.

\begin{itemize}
\item Which outcomes are in $(A \cup B)^C$?
\end{itemize}
%% don't know what to do here, these are the three events that are in neither A nor B





We should be able to verify standard operations such as:
\begin{itemize}
\item $A \cap B$: HHH
\item $A \cup B$: HHH, TTT, HTH, HHT, THH
\item $B^C$: TTT, TTH, THT, HTT
\item $(A \cup B)^C$: TTH, THT, HTT
\end{itemize}



John Venn has in interesting family background, see \href{http://www-groups.dcs.st-and.ac.uk/history/Biographies/Venn.html}{\color{blue}MacTutor article on John Venn}.

%% I don't think I'd cover this in a lecture

\subsubsection{Commutation and association}

Some mathematical properties of sets.


Commutativity:
\begin{itemize}
\item $A \cup B = B \cup A$
\item $A \cap B  = B \cap A$
\end{itemize}


Associativity:
\begin{itemize}
\item $A \cup B \cup C = (A \cup B) \cup C = A \cup (B \cup C)$
\item $A \cap B \cap C = (A \cap B) \cap C = A \cap (B \cap C)$
\end{itemize}

Distributivity:
\begin{itemize}
\item $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$
\item $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$
\end{itemize}






This material will get covered more formally in a pure maths course, hopefully we can see how these can be used as the basis for probability.



\section{Problems}
\begin{enumerate}
\input{Problems/dummy2/Set1_SampleSpaces.tex}
\input{Problems/dummy2/Set1_CoinTossing.tex}
%\input{Problems/dummy2/Set1_Venns1.tex}
%\input{Problems/dummy2/Set1_Venns2.tex}
\input{Problems/dummy2/Set1_DeMorgan.tex}
\end{enumerate}


%%%%%%%%%%
%%% Chapter 3 Naive definition 
%%%%%%%%%% Very short chapter

\chapter{The naive definition of probability}

\section{Na\'ive definition of Probability}

\textit{This is covered in section 1.3 of Blitzstein and Hwang}

Consider a random experiment with a finite number of outcomes, each with the same probability.   For event $A$, we claim that:

\begin{displaymath}
\mbox{Probability of an event} = \frac{\mbox{Number of possible sample points consistent with this event}}{\mbox{Total number of sample points}}
\end{displaymath}

Or in a better notation:

\begin{equation}
P[A] = \frac{n[A]}{n[\Omega]}
\end{equation}
where $A$ denotes the event we are interested in, $n[A]$ is the number of ways in which $A$ can happen and $n[\Omega]$ is the number of events in the sample space.  


Recall from our first Venn diagram, where we used $A^C$ to denote the \emph{complement} of $A$ (i.e. those outcomes that weren't in $A$), then the probability of $A^C$ (probability that $A$ doesn't happen), $P[A^C]$ is:

\begin{displaymath}
P[A^C] = 1 - P[A]
\end{displaymath}


Likewise, if we consider the second Venn diagram, and consider that $P[B]$ denotes the probability of event $B$ happening we have:

\begin{itemize}
\item $P[A \cup B]$: probability that event $A$ or event $B$, or both happens
\item $P[A \cap B]$: probability that both $A$ and $B$ happen
\end{itemize}


\begin{enumerate}
\input{Problems/dummy3/Set1_ValidProb.tex}
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% Perms and Combs Chapter 4
%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Counting rules OK}

\textit{This is covered in section 1.4 of Blitzstein and Hwang}

We've spent a lot of time looking at dice and coins.   If we have 3 dice indexed $i=1,2,3$ each of these three dice can show one of $n_i=6$ faces.   Together the number of possible outcomes are given by $n_1 \times n_2 \times n_3 = 6^3$.   (And using our na\"ive definition of probability we would say each outcome can occur with probability $\frac{1}{6^3}$).   However, drawing tree diagrams to explore the sample space is rather tedious.   We need some ideas that can let us evaluate the number of possible outcomes in a more efficient manner.



\section{First Rule of Counting}

We wish to set out the principles as generally as possible, in order that we can apply them beyond the ``standard formulae''.

\subsubsection{N-tuple}

Consider that we have $k$ objects with size  $n_i$, $i=1, \dots k$.

\begin{df}
An N-tuple is a finite ordered set with an unspecified number of members
\end{df}

A specific example would be a 5-tuple which is an ordered set with 5 members.   How many ways can we form such a Tuple?

\begin{tm}
If a task consists of $k$ separate tasks, the $i$th of which can be done in $n_i$ ways $i=1,\ldots,k$ then the entire job can be done in $n_1 \times n_2 \times \cdots \times n_k$ ways
\end{tm}

\fbox{
\begin{minipage}[c]{0.9\textwidth}
Proof for $k=2$.   If the first task can be done in $n_1$ ways, then for each of these ways we have $n_2$ choices for the second task.   Thus we can do the job in 

$\underbrace{(1 \times n_2) + (1 \times n_2) + \dots + (1 + n_2)}_{n_1 \mbox{ terms }} = n_1 \times n_2$
\end{minipage}
}


Suppose that each outcome (i.e., element) of $A$ takes the form of an n-dimensional vector (or n-tuple) such as ($a_1, a_2, \ldots a_n$).   If there are $N_1$ objects that can be used for $a_1$, and $N_2$ for $a_2$ then:

\begin{equation}
n(A) = N_1N_2 \ldots N_n   
\end{equation}
assuming that sets $A_1, A_2, \ldots A_k$ have respectively $n_1, n_2, \ldots, n_k$ different ways in which one can first take an element of $A_1$, then an element of $A_2$ and so on.


Imagine a factory where you have $15$ electricians, $8$ machine operators and $4$ supervisors.   How many ways can you arrange a shift of three staff.  We have $N_1 = 15$, $N_2=8$ and $N_3=4$, with $15 \times 8 \times 4 = 480$.  This is rather an intuitive result, but it seems too convenient to be true that we needed exactly one maintenance person, one production person and one supervisor.   




\section{Some common scenarios}

We consider two scenarios:
\begin{itemize}
\item Permutations (the order of the elements is important)
\item Combinations (the order of the elements is not important)
\end{itemize}

Within each scenario, we consider two types of sampling:
\begin{itemize}
\item Sampling with replacement (for example with dice or coins, if we use a second roll/throw, we have the same number of possible outcomes)
\item Sampling without replacement (for example with cards, once we have removed a card from a pack of (say) $n=52$ cards, on the next draw we have $n-1=51$ cards to choose from
\end{itemize}



 



\fbox{\begin{minipage}[c]{1.0\textwidth}
\textbf{Summary of key formulae}

(Do note it's better to be able to derive these from first principles)

\begin{tabular}{lcc}
& With replacement & Without replacement \\
Ordered & $n^k$ & $\frac{n!}{(n-k)!}$ \\[1.2ex]
Unordered & $\binom{n+k-1}{k}$ & $\binom{n}{k}$\\[1.2ex]
\end{tabular}

Where $\binom{a}{b}$ denotes $\frac{a!}{b!(a-b)}$

\end{minipage}
}


 


\subsection{Permutation: Ordered sets}



Given a population of $n$ distinct elements, we wish to count how many ways are there of creating $r$ ordered samples?   We can easily do both with and without replacement.

\begin{itemize}
\item[(i)] with replacement: $n^r$ (this is an immediate application of first rule of counting where $n_1=n_2=\cdots=n_k$)
\item[(ii)] without replacement $n(n-1)(n-2)\ldots(n-r+1)$,  calculation reduces to: $\frac{n!}{(n-r)!}$ (this is also an application of the first rule of counting, but clearly the $n_2=n_1-1$ because of the lack of replacement)
\end{itemize}

\begin{eqnarray*}
&=& n(n-1)(n-2)\ldots(n-r+1) \\
&=& \frac{ {\color{red} n(n-1)(n-2)\ldots(n-r+1)} {\color{blue} (n-r)(n-r-1)(n-r-2)\ldots(1)}}{{\color{blue} (n-r)(n-r-1)(n-r-2)\ldots(1)}} \\
&=& \frac{n!}{(n-r)!}
\end{eqnarray*}

%(that's probably a dumb way of calculating it, but a very neat way of writing it)

%Note, if we want to know all possible ways of arranging $n$ items we just need $\frac{n!}{n-n!} = n!$

 

 

\section{Combinations}

\subsection{Unordered sets}

Recall that two sets are regarded as disjoint if and only if the properties of the membership are mutually exclusive.  

\begin{df}
A \emph{partition} is defined as a set of disjoint and exhaustive subclasses of a given class that is divided in such a way that each member of the given class is a member of exactly one such subclass.
\end{df}
 

\subsection{Without replacement}

We can think of this in two ways.   Firstly we can consider the number of ways we can form an object of size $r$ from a set of  $n$ objects where we don't care about the ordering (think card playing, team selection).   However, much more generally we could think of how many ways could we select $r$ beads from an urn of $n$ beads.   We can't distinguish the beads in practice, but in theory we can so in general this can be thought of as the number of ways a set of $n$ objects can be partitioned into 2 distinct subsets of size $r$ and $n-r$.

\begin{equation}
{n \choose r} = \frac{n!}{r!(n-r)!}
\end{equation}

(This is what Baclawski calls the Shepherd principle.   If you get tired counting sheep, count the legs and divide by four.   We saw above that there were $\frac{n!}{(n-r)!}$ different ordered sets, we need to divide by the $r!$ different orderings of each combination)

\subsubsection{Important shorthand: $n$ choose $r$}

This is such an important idea that it has it's own shorthand:

\begin{displaymath}
\frac{n!}{r!(n-r)!} = \binom{n}{r}
\end{displaymath}

(This might be a different notation to the one you have used previously)



\subsubsection{Side issue 1: Partitioning into k-subsets}

The number of ways a set of $n$ objects can be partitioned into $k$ distinct subsets, where set 1 has $r_1$ elements, set 2 has $r_2$ elements, \ldots, set $k$ has $_k$ elements is:

\begin{equation}
\frac{n!}{r_1!r_2! \ldots r_k!}
\end{equation}

(Exercise: Show that the standard $\binom{n}{r}$ is a special case of this formula)


%\subsection{Permutations and combinations}

%Consider the probability of getting two of a kind and three of a kind when rolling five dice e.g., $(2,2,5,5,5)$ or $(4,4,1,1,1)$.   If we denote the number on the $i$th die by $n_i$, we have a sample space that consists of all the ordered 5-tuples ($n_1, n_2, n_3, n_4, n_5$) we have $n(\Omega)=6^5$.   Now introduce an ordered pair $(i,j)$ where $i$ is the number appearing twice, and $j$ the number that appears three times.  There are $\frac{6!}{(6-2)!}$ ways of obtaining 



 
\subsubsection{Side issue 2: Pascal's Triangle}

It's not worth losing sleep over, but it's impossible at this stage not to mention Pascal's\footnote{apparently discovered by Jia Xian in 1050, published by Zhu Shije in 1303, discussed by Cardano in 1570} triangle:

\begin{footnotesize}
\begin{tabular}{rrrrrrrrrrrrrrr}
 & &  &  &  &  &  &1 &  &  &  &  & &\\
 & &  &  &  &  & 1&  &1 &  &  &  & &\\
 & &  &  &  & 1&  &2 &  & 1&  &  & &\\
 & &  &  & 1&  &3 &  &3 &  &1 &  & &\\
 & &  & 1&  &4 &  &6 &  &4 &  &1 & &\\
 & &1 &  & 5&  &10&  &10&  & 5&  &1& \\
 &1&  &6 &  &15&  &20&  &15&  & 6& & 1\\
1& & 7&  &21&  &35&  &35&  &21&  &7&1
\end{tabular}
\end{footnotesize}

Note that each number in the triangle is the sum of the two numbers either side of it in the row above.   Now consider you have a pool of $7$ objects, and wish to know how many different ways there are of arranging them into sets of $3$.   We used above ${n \choose r} = {7 \choose 3} =  \frac{7!}{3!(7-3)!} = 35$.   However, if we number the rows of Pascal's triangle from 0 (at the top) to 7, take row 7 and count along to the 4th entry, we have 35.   Isn't that cute?


 

\subsection{Combinations: Undordered with replacement}

To keep this simple let's roll a die three time, and work out something like the probability of getting two faces showing $3$ and one showing $6$.   Let's illustrate the idea as:

\begin{tabular}{lr|r|r|r|r|r}
Face & 1 & 2 & 3 & 4 & 5 & 6\\
Hits &   &   &Y Y&   &   & Y
\end{tabular}

Note how this reduces to a problems of bins and walls such that we can specify this particular arrangement as:

$||YY|||Y$

Note we have walls between $1$ and $2$, between $2$ and $3$, then two entries in the bin marked $3$.   This problem is therefore equivalent to finding an ordered arrangement of $n$ items and $k-1$ walls hence the number of combinations is given by:

\begin{displaymath}
\binom{n+r-1}{r}
\end{displaymath}



 


%\subsection{A word problem}

%Just to convince you that these problems don't just consist of finding the right formulae from the four given above, here is related idea (which you can easily solve if you think a little).   Consider the manager of a small plant wishes to determine the number of ways which he can assign staff to the first shift.   There are $15$ staff who can serve as operators of the production equipment, $8$ who can serve as maintenance personnel and $4$ who can be supervisors.

%If a shift requires one operator, one maintenance person and one supervisor, how many different ways can the shift the staffed?    The answer is $480$, which is rather tedious if one had to draw the tree diagram, and doesn't quite fit the formulae above, although the principles set out there do apply.

 

 

%\subsection{Side issue: Bose Einstein}

%Imagine tossing two coins, but the coins have three faces (H, T, S).   If you were asked for the sample space of such an experiment you might say there are 9 events in the sample space.

%\begin{itemize}
%\item[] $H_1, H_2$
%%\item[] $T_1, T_2$
%\item[] $S_1, S_2$
%\item[] $H_1, T_2$ and $T_1, H_2$ 
%\item[] $H_1, S_2$ and $S_1, H_2$ 
%\item[] $T_1, S_2$ and $S_1, T_2$
%\end{itemize}

%By the naive definition, we have $P(\mbox{One head, one tail})=\frac{2}{9}$.
% 

%Very roughly speaking, you could imagine a simple gas made up of two particles (two coins), each of which can take on one of three quantum states (here $H$, $T$ or $S$).   As I understand it, this situation above roughly corresponds to Maxwell-Boltzmann statistics.   The fascinating thing is that under Bose-Einstein statistics, the particles (coins) are indistinguishable, and under Bose-Einstein you might say we would have a sample space:
% 

%\begin{itemize}
%\item[] $H,H$
%%\item[] $T,T$
%\item[] $S,S$
%\item[] $H,T$
%\item[] $H,S$
%\item[] $T,S$
%\end{itemize}

%and if this were indeed a sample space then $P(\mbox{One head, one tail})=\frac{1}{6}$.   This seems to trash 100 years of mediaeval work on the enumeration of sample spaces.   Neverthless, Bose-Einstein did rather a lot more work and predicted a ``condensate'' which was discovered experimentally 70 years after their theoretical work.


%You can rest assured that there will be no exam questions on Bose-Einstein.   The reason for mentioning this is really to highlight the importance of probability within quantum physics, and to admit that physicists develop the basic idea in a very different direction to statisticians.


\section{Circular permutations}


This is an important topic in other branches of mathematics, and I've seen questions around this topic in a lot of online numeracy tests.  The key idea is one of redundancy.   

\subsection{Clockwise and anti-clockwise order matters (tables)}

We are going to consider permutations (the order matters) around a dinner table.   The clue to the problem is that there is only one way of looking at a dinner table (from the top).  


\subsection{Clockwise and anti-clockwise order matters (tables)}

The rather dated idea here is that we are placing guests on a dinner table for a party.   If we sketch the problem.


\begin{minipage}[t]{.45\textwidth}
\textbf{Dinner party 1}

\begin{tikzpicture}

\def \n {4}
\def \radius {3cm}
\def \margin {8} % margin in angles, depends on the radius

\foreach \s in {1,...,\n}
{
\SUBTRACT{\s}{1}\a
  \node[draw, circle] at ({360/\n * (\s - 1)}:\radius) {$\a$};
  \draw[-, >=latex] ({360/\n * (\s - 1)+\margin}:\radius) 
    arc ({360/\n * (\s - 1)+\margin}:{360/\n * (\s)-\margin}:\radius);
}
\end{tikzpicture}
\end{minipage}%
\begin{minipage}[t]{.45\textwidth}
\textbf{Dinner party 2}

\begin{tikzpicture}

\def \n {4}
\def \radius {3cm}
\def \margin {8} % margin in angles, depends on the radius

\foreach \s in {1,...,\n}
{
\ADD{\s}{1}\a
\INTEGERDIVISION{\a}{4}{\zzz}{\b}
  \node[draw, circle] at ({360/\n * (\s - 1)}:\radius) {$\b$};
  \draw[-, >=latex] ({360/\n * (\s - 1)+\margin}:\radius) 
    arc ({360/\n * (\s - 1)+\margin}:{360/\n * (\s)-\margin}:\radius);
}
\end{tikzpicture}
\end{minipage}

If we moved the table by 180 degrees (assuming the chairs are fixed to the table) both settings are identical.   In other words, the first position is redundant.   Hence, we can find the number of permutations using $(n-1)!$


Example: How many ways are there of arranging 8 dinner party guests around a circular table?

Solution: $(8-1)! = 7!$

Example. Now imagine we have a dinner party involving 8 mixed gender couples (male female).   How many ways are there of arranging the dinner party so that we have alternate gender seating.

Solution.   We pick a gender at random and start allocating them.   As it is a circular table we have four options for the first position and then four options for the alternate gender person sitting next to them.   However, the sitting positions are redundant so we only need to consider the next person.   There are 3 possibilities for the next position, and 3 possibilities for their partner, with 2 and 2 for the next position and 1 and 1 for the final position.   In other words, the problem reduced to $3! \times 4!$ possibilities.


\subsection{Clockwise and anti-clockwise doesn't matter (necklaces)}

An extension to the previous problems is where we regard clockwise and anti-clockwise positions as equivalent.   The conventional word problem involves a necklace, and the logic is that you can look at a necklace from either side.   

These problems are a simple extension to the dinner table problems in that we only need apply the shepherd principle (divide by the number of ways we can look at the necklace).

\begin{tikzpicture}

\def \n {4}
\def \radius {3cm}
\def \margin {8} % margin in angles, depends on the radius

\foreach \s in {1,...,\n}
{
\MULTIPLY{\s}{-1}\a
\ADD{\a}{4}\b
  \node[draw, circle] at ({360/\n * (\s - 1)}:\radius) {$\b$};
  \draw[-, >=latex] ({360/\n * (\s - 1)+\margin}:\radius) 
    arc ({360/\n * (\s - 1)+\margin}:{360/\n * (\s)-\margin}:\radius);
}
\end{tikzpicture}

You have to consider whether this is equivalent to the previous representation if you were looking at the circular arrangement from the opposite side.   If so, the number of permutations is given by:

$\frac{(n-1)!}{2!}$


\subsection{Fusions}


The general idea is that we have a simple restriction on the number of permutations we seek.   For example, if at a G7 summit we wanted to consider how many ways we can line up the seven world leaders such that George and Tony are standing next to each other.

We split this into two problems
\begin{itemize}
\item Fuse together the object (George and Tony) as if one object, and work out how many ways there are of arranging the resulting objects (in this case there are six objects, so there are $6!$ permutations)
\item Then multiply by the number of ways you can un-fuse the object.   There are $2!$ ways we can stand George and Tony next to each other
\item There are therefore $6!2!$ ways in which we can arrange seven world leaders such that George and Tony are standing next to each other.
\end{itemize}


\section{Problems}

\begin{enumerate}
\input{Problems/dummy4/Comb1_CommitteeGender.tex}
\input{Problems/dummy4/Comb1_Committee.tex}
\input{Problems/dummy4/Comb1_Lottery.tex}
\input{Problems/dummy4/Comb1_AngelinaJolie.tex}
\input{Problems/dummy4/Comb1_AngelinaJolie2.tex}
\input{Problems/dummy4/Comb1_AngelinaJolie3.tex}
\input{Problems/dummy4/Comb1_AngelinaJolie4.tex}
\end{enumerate}


Using the counting rules in probability (naive definition)

\begin{enumerate}
\input{Problems/dummy3/Naive_family.tex}
\end{enumerate}


Chapter 1, Problems 1 to 14 of Blitzsein and Hwang give more practice at working with counting.  Problems 21 to 40 give further practice of counting combined with the naive definition of probability.  


\chapter{A non-naive definition of probability}

\textit{This is covered in Section 1.6 of Blitzstein and Hwang.}

\section{The Axioms of Probability}

The system of probability we have been working through took a long time to develop, and wasn't fully formalised until the 1930's by Kolmogorov (see 
\href{http://www.gap-system.org/~history/Biographies/Kolmogorov.html}{\color{blue}www.gap-system.org/~history/Biographies/Kolmogorov.html}).   He stated three fundamental Axioms, from which all other results can be derived.



\fbox{
  \begin{minipage}[c]{1.0\linewidth}
\begin{itemize}
\item $P[A] \geq 0$ for any event $A$
\item $P[\Omega] = 1$ where $\Omega$ is the sample space 
\item If $[A_i];i=1,2,\ldots$ are mutually exclusive then $P[A_1] \cup P[A_2] \cup \ldots = P[A_1] + P[A_2] + \ldots$
\end{itemize}
\end{minipage}
}

Mutually exclusive means that $A_i \cap A_j = \emptyset$ for all $i \neq j$


We shall examine the implications of these Axioms in terms of obtaining mathematical functions that can serve as models for probability (probability distribution functions) in week 2.   The intuitive consequences of these results are:

\begin{itemize}
\item (Non-negative) Probability can never be negative
\item (Total probability) The probability of a sample space must equal 1 
\item (Countable additivity) The probability of observing two (or more) mutually exclusive events is the sum of their individual probabilities
\end{itemize}

However, we need to derive some additional results from these Axioms in order to be able to carry out useful probability calculations.



\subsection{Deriving $P(A^C)$}

The sets $A$ and $A^C$ form a partition of the sample space so that $\Omega = A \cup A^C$.   We therefore know by the second axiom that $P(A \cup A^C) = 1$.   By the third axiom we know that $P(A \cup A^C) = P(A) + P(A^C)$ so we can rearrange this to give:

\begin{align*}
P(A \cup A^C) &= P(A) + P(A^C) \\
P(A \cup A^C) - P(A) &= P(A^C) \\
P(A^C) &= 1 - P(A)
\end{align*}

\subsection{Deriving $P(A) \leq 1$}

If $P(A^C) \geq 0$ and $P(A) + P(A^C) = 1$ this is immediate.

\subsection{Deriving the addition rule}

Consider the set $B$, which we can expand as $B=(B \cap A) \cup (B \cap A^C)$.   This tells us (eventually) that

\begin{displaymath}
P(B) = P(B \cap A) + P(B \cap A^C)
\end{displaymath}
Note that the two terms on the right hand side are disjoint so we can use the third axiom.

Now we want to think about $A \cup B = A \cup (B \cap A^C)$, again the two terms on the right hand side are mutually exclusive/disjoint.   

\begin{align*}
P(A \cup B) &= P(A) + P(B \cap A^C) \\
 &= P(A) + P(B) - P(A \cap B)
 \end{align*}



You can verify this; draw the Venn Diagram.   If we merely added $p[A]$ to $p[B]$ for events with an intersection, we would add the probability corresponding to $p[A \cap B]$ twice, and hence we need to subtract one of these areas.

{\color{green}What does this tell us about the value of $p[A \cap B]$ for for mutually exclusive events?}


\section{Problems}
\begin{enumerate}
\input{Problems/dummy5/Set1_AdditionRuleProof.tex}
\input{Problems/dummy5/Set1_AdditionRule.tex}
\input{Problems/dummy5/Set1_LoadedDie.tex}
\input{Problems/dummy5/Set1_Options.tex}
\input{Problems/dummy5/Set1_BasicSets.tex}
\input{Problems/dummy5/Set1_WhichTyre1.tex}
\input{Problems/dummy5/Set1_WhichTyre2.tex}
\end{enumerate}


Problems 41 to 46 in Blitzstein and Hwang give further practice.   Then problems 54 to 60 consolidate all aspects of the introductory parts of this module.


%%%%%%%%%%%%%%%%%%%
%%%%%%% CONDITIONAL PROBABILITY
%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conditional Probability}

\textit{This is covered in chapter 2 of Blitzstein and Hwang.}

Actually, all probability is conditional, it just gets tedious to write $P(X|\Omega)$.   The key to using probability correctly is to condition correctly.   
We wish to find out how we update probability (or belief!!!!) in the presence of additional information.

\begin{itemize}
\item To examine conditional probability
\item To define the term ``independence'' a little more precisely
\item To state the law of total probability
\item To state Bayes Theorem
\end{itemize}


% 


 

\section{Conditional probability - why the fuss}

For full details of these problems see Leonard Mlodnikov ``A drunkard's walk'', a lovely popular science book.

\begin{itemize}
\item Make the simplifying assumption that $P(\mbox{Baby is boy}) = 0.5$ and $P(\mbox{Baby is girl=0.5})$.
\item Consider a two child family.   You know that one child is a girl.   What is the probability that the other child is a girl?
\item Consider a two child family.   You know that one child is a girl called Mirabehn.   What is the probability that the other child is a girl
\end{itemize}

For a more formal, exam relevant coverage of this material see Chapter 4 in Blitzstein and Hwang

 

\subsection{Solution 1}

Hopefully you gave the na\"ive answer $0.5$.   Now consider the (also slightly na\"ive) take on the sample space for a two child family which consists of:

\begin{tabular}{r}
BB \\
{\color{red}BG} \\
{\color{red}GB}\\
{\color{red}GG}
\end{tabular}

So hopefully you see the ``correct'' answer is $\frac{2}{3}$, as we should condition on the three events where a family has a girl.

 

\subsection{Solution 2}

Here I simplify a little, and don't explain some of the simplifications in these notes (ask me or see Mlodnikov).   Denote $G_M$: a girl called Mirabehn and $G_N$ and girl not called Mirabehn.

\begin{tabular}{rr}
$G_N$ $G_M$ &  \\
$G_M$ $G_N$ &  \\
$G_M$ $B$   & $G_N$ $B$ \\
$B$ $G_M$  & $B$ $G_N$ \\
$G_M$ $G_M$ & $G_N$ $G_N$\\
 & $B$ $B$ \\
\end{tabular}

(As it stands, that is no equal probability sample space, but by choosing a rare name when we choose only those events featuring $G_M$ we get some closeness to four events of similar probability - assuming we can discard the possibility of two girls of the same name).   

Note when we condition on $G_M$ we get four events, two of which feature a second girl so the probability is (approximately) $\frac{1}{2}$

  

\subsection{Conditional probability defined}

Hopefully, that little exercise has convinced you conditional probability is a topic where you need to be fully alert!   Most of the fun comes from carefully specifying and identifying the event on which you are conditioning.   But it's not all nuisance, being able to condition also helps us solve many problems.


To date, we have only considered information obtained from:


\begin{itemize}
\item[(a)] Specifying the sample space and
\item[(b)] explicitly or implicitly (or na\"ively) specifying a probability measure on that sample space
\end{itemize}

However, knowledge that a particular event has taken place can alter our assessment of the probability of other events.   Consider a student who wishes to pass his course.   However, this student doesn't like attending lectures.   he is told that his chances of passing the course will increase if he attends lectures.

We can write this \emph{conditional probability} as:
\begin{displaymath}
P[\mbox{Student will pass course} | \mbox{Student attends lectures}]
\end{displaymath}

 

You have previously examined the situation where we could examine $A$ (the event that the student attends passes, the circle on the left), $B$ (the event that the student attends, the circle on the right) as well as the intersection.   We could draw a Venn diagram something like the one below:


\def\firstcircle{(0,0) circle (1.5cm)}
\def\secondcircle{(0:2cm) circle (1.5cm)}

\colorlet{circle edge}{blue!50}
\colorlet{circle area}{blue!20}

\tikzset{filled/.style={fill=circle area, draw=circle edge, thick},
    outline/.style={draw=circle edge, thick}}

\setlength{\parskip}{5mm}
% Set A and B
\begin{tikzpicture}
\begin{scope}[fill opacity=0.5]
        \clip \secondcircle;
        \draw[outline, even odd rule] \firstcircle
                                     \secondcircle node {$B$};
    \fill[red] \secondcircle;
    \end{scope}
    \draw[outline] \firstcircle node {$A$}
                   \secondcircle;
    \node[anchor=south] at (current bounding box.north) {$B \cap A$};
\end{tikzpicture}    


%\includegraphics[width = 0.3\textwidth]{venn1}

However, once we know that the student has indeed attended lectures, the information we have on the problem changes the question.   We are no longer interested in $B^C$, as we know the student attended.   Hence, we {\color{green}\emph{condition}} our interest on $B$


We therefore want to know the probability of the student passing, given that we know (s)he attended lectures.

%\includegraphics[width = 0.3\textwidth]{venns}


We can use the following statement:

\begin{df}
\begin{displaymath}
P[A|B] = \frac{P[A \cap B] }{P[B]} \mbox{ if } P[B] > 0
\end{displaymath}
\end{df}
to solve this problem.   This expression is undefined if $p[B] = 0$

 

In frequency terms, this expression can be thought of as:

\begin{displaymath}
\frac{\mbox{Number of experiments in which both A and B occurred}}{\mbox{Number of experiments in which B occurred}}
\end{displaymath}



 


 

%\subsection{Axioms of conditional probability}

%As with probability, we only need a few axioms for conditional probability.   
%%(See Amemiya, 1994, page 10, who provides the argument that you only need one axiom from which the others can be drawn)

%\begin{df}Axioms of conditional probability:

%\begin{itemize}
%\item $p[A|B] \geq 0$ for any event $A$
%\item $p[A|B] \leq 1$ for any event $A \supset B$
%\item If $A_1, A_2, \ldots$ is a sequence of mutually exclusive events then: $p[A_1 \cup A_2 \cup \ldots | B] = p[A_1|B] + p[A_2|B] + \ldots$
%\item If $A_1 \supset B$ and $A_2 \supset B$ and $p[B] \neq 0$ then $\frac{p[A_1|B]}{p[A_2|B]} = \frac{p[A_1]}{p[A_2]}$
%\end{itemize}

%\end{df}

%It can be seen that conditional axioms (1), (2) and (3) are analogous to the axioms of probability.   The fourth axiom tells us that the relative frequency $A_1$ versus $A_2$ remains the same after $B$ has happened. 

 
\subsection{Consequences}

A few small points worth mentioning:

\begin{itemize}
\item $P[B|B] = 1$
\item $P[A^C|B] = 1 - P[A|B]$
\item $P[A_1 \cup A_2 | B] = P[A_1|B] + P[A_2|B] - P[A_1 \cap A_2 | B]$
\end{itemize}

But let's really have some fun with our main definition:



%But we have an additional theorem that is specific to conditional probability and quite useful:
\begin{df}
For any pair of events $A$ and $B$, where $P[B] > 0$:
\begin{displaymath}
P[A|B] = \frac{P[A \cap B]}{P[B]}
\end{displaymath}
\end{df}


 

Let's start by multiplying both sides by $p(B)$

\begin{displaymath}
P[A|B]P[B] = P[A \cap B]
\end{displaymath}

Now let's note that the labels $A$ and $B$ are arbitrary.   So it must also be true that
\begin{displaymath}
P[A \cap B] = P[B|A]P[A]
\end{displaymath}

In other words we have shown that

\begin{displaymath}
P[A|B]P[B] =  P[B|A]P[A]
\end{displaymath}
and if I divide both sides by $P[B]$ I have just proved Bayes' Theorem (which we define more carefully later).
%\begin{df}
\begin{displaymath}
P[A|B] = \frac{P[B|A]P[A]}{P[B]}
\end{displaymath}

 

We need to say more about that $P[B]$ denominator, but first let's illustrate the key idea with natural frequencies.   Consider a dread disease, and consider that $1$ person in $10,000$ has this disease.   Now consider a screening test for that disease, if you have the disease, it will detect it with probability $0.95$.   If you don't have it, it will give you the all clear with probability $0.9$.   

Now imagine you have gone to your physician, done the test, and been told you have the disease.   Should you be worried?

 

First time round, let's consider this problem with natural frequencies.   Let's invent a population as follows:

\begin{tabular}{rrrr}
 & Disease & No disease & Total \\
Test positive \phantom{95} & \phantom{99,990} & \phantom{100,085} \\
Test negative \phantom{5} & \phantom{899,910} & \phantom{899,915} \\
Total & 100 & 999,900 & 1,000,000
\end{tabular}

So, as you can see, with $1$ in $10,000$ having the disease, our ficitional population of $1,000,000$ has $100$ cases with the remainder being non-cases.

 

Now, we were told that if you have the disease (if you are one of the $100$ people), the test will detect it $0.95$ of the time.   So let's fill in these numbers:

\begin{tabular}{rrrr}
 & Disease & No disease & Total \\
Test positive & 95 & \phantom{99,990} & \phantom{100,085} \\
Test negative & 5 & \phantom{899,910} & \phantom{899,915} \\
Total & 100 & 999,900 & 1,000,000
\end{tabular}

So, as you can see, with $1$ in $10,000$ having the disease, our ficitional population of $1,000,000$ has $100$ cases with the remainder being non-cases.

The next step will be to do the same for the people who don't have the disease:


 

It's becoming obvious I think where this is going.   Look at the effect of adding $0.1$ of the disease free individuals to the row that test positive.  So we've leapt into adding the row totals.

\begin{tabular}{rrrr}
 & Disease & No disease & Total \\
Test positive & 95 & 99,990 & 100,085 \\
Test negative & 5 & 899,910 & 899,915 \\
Total & 100 & 999,900 & 1,000,000
\end{tabular}


So now, if I want the probability that I have the disease, given I tested positive, it is $\frac{95}{100,085}$ which is about $0.000949$.    Not much to worry about really!!!

Hopefully this explains the concept (Psychologists sometimes call this Baseline Bias), but we want to be a little more mathematical in our approach.



\subsection{Law of alternatives}

The only problem with the derivation given is that I've been a bit glib about where $p[B]$ came from.   Now we only know that one of several possible events $A_1$,$A_2$, $\ldots$ has occured (there may be infinitely many of these alternatives).

\begin{df}[The Law of Total Probability]

(We will illustrate this with a Venn diagram in the lecture)

If
\begin{itemize}
\item $A_i$ $i \geq 1$ are pairwise disjoint
\item $P(\bigcup_i A_i)=1$ (we sometimes require the condition that $\bigcup_i A_i = \Omega$
\item $P(A_i)>0$ for every $i$
\end{itemize}
then
\begin{displaymath}
P(B)=P(B|A_1)P(A_1) + P(B|A_2)P(A_2) + \cdots
\end{displaymath}

\end{df}

 
\subsection{Bayes Theorem}

This is rather an important theorem, and follows from the above.   As stated here, this theorem is a well accepted argument.

\begin{df}
Let events $A_1, A_2, \ldots, A_n$ be mutually exclusive, such that $P[A_1 \cup A_2 \cup \ldots \cup A_n] = 1$ and $P[A_i] > 0$ for each $i$.   Let $B$ be an event such that $P[B] > 0$.  Then:

\begin{displaymath}
P[A_i | B] = \frac{P[B|A_i]P[A_i]}{\sum_{j=1}^n P[B|A_j]P[A_j]}, i=1,2,\ldots, n
\end{displaymath}
\end{df}

 

As stated, Bayes theorem is a very simple and widely accepted result in conditional probability.   Occasionally we use the following terminology:

\begin{itemize}
\item Prior probability: $P[A_i]$
\item Posterior probability $P[A_i | B]$
\end{itemize}


Where Bayes theorem starts to get interesting is when we no longer use simple probabilities in the calculations.  Specifically, when we start using the likelihood as $P[B|A_i]$ we can carry out some very interesting inference.

\section{Problems}

\begin{enumerate}
\input{Problems/dummy6/Cond1_ThreeUrnsRed.tex}
\input{Problems/dummy6/Cond1_LifeTables.tex}
\input{Problems/dummy6/Cond1_LifeTables2.tex}
\input{Problems/dummy6/Cond1_LifeTables3.tex}
\input{Problems/dummy6/Cond1_BayesRuleProof.tex}
\input{Problems/dummy6/Cond1_BonzoFonzoGonzo.tex}
\input{Problems/dummy6/Cond1_IoA1.tex}
\input{Problems/dummy6/Cond1_IoA2.tex}

\input{Problems/dummy6/Cond1_ThreeUrnsGreen(Conditional).tex}

\end{enumerate}

Any of the 65 problems at the end of chapter 2 in Blitzstein and Hwang will give you great practice to make sure you understand this topic.

%%%%%%%%%%%%%%%%%%%%
%%%% Discrete functions
%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Discrete Probability Functions}

\textit{This is covered in sections 3.1 and 3.2 of Blitzstein and Hwang.}

\section{Variables}

Variables can be classified in all kind of ways:
\begin{itemize}
\item Quantitative (where the values taken are numerical:
  \begin{itemize}
  \item Discrete (only particular values are possible, e.g. the
    integers)
  \item Continuous (where any value in a range is possible)
  \end{itemize}
\item Qualitative (where the object has some non-numerical quality)
  \begin{itemize}
  \item Ordinal (where these qualities can be ordered)
  \item Categorical (where the qualities are simply of different
    types, e.g., red bicycle, blue bicycle)
  \end{itemize}
\end{itemize}


In terms of defining probability measure, we 
only worry about the two
types of \emph{quantitative} variable listed; discrete and continuous.  
We can only work with qualitative variables for example if we measure
them or count them.


\fbox{
\begin{minipage}[c]{1.0\textwidth}
\begin{itemize}
\item A discrete random variable is a variable that takes a countable
  (this can be countably finite or countably infinite)
  set of real numbers with associated probabilities
\item A continuous random variable is a variable which takes a
  continuum of values in the real line according to a rule determined
  by a density function
\end{itemize}
\end{minipage}
}



This chapter concentrates on discrete random variables.




\section{Mass and distribution}

Having carried out some experiment, we know the particular outcome $\omega \in \Omega$, and can assign a value to $X(\omega)$.   We wish to assign some measure of probability to this eventually, and can do this either using a mass function:

\begin{itemize}
\item $p(k)$=probability that $X$ is equal to $k$ where $k \in \mathbb{Z}$
\end{itemize}

or more usefully through a distribution function:

\begin{itemize}
\item $F(k)$=probability that $X$ does not exceed $x$ where $x \in \mathbb{R}$
\end{itemize}

Do note the convention $p(k)$ and $F(x)$.


\fbox{
\begin{minipage}[c]{1.0\textwidth}
\textbf{Vital notation}
\begin{itemize}
\item[] $X$ (upper case) a random variable
\item[] $k$ (lower case) a realization of a random variable
\item[] $p(k)$ Probability Mass Function $P(X=k)$
\item[] $F(x)$ Cumulative Distribution Function $P(X \leq x)$
\end{itemize}
\end{minipage}
}

So far our discussion has been in terms of discrete variables.   It seems appropriate to refresh ideas about discrete and continuous variables before going further.




\subsection{Discrete random variables}


A frequentist interpretation would suggest that a random variable (usually denoted by a capital letter) is a numerical variable ``defined'' by the outcome of a random experiment.   Even the experiment hasn't happened, we evaluate relative to some sense of a long run of experimental outcomes.   


We are interested in knowing something about the event that a random variables $X$ took on a particular value $k$ i.e  $A: \left\{ X=k \right\}$ and the probability $P[X=k]$ associated with that event.

\begin{df}
A \emph{discrete} random variable is a real valued function defined on the
sample space $\Omega$ where the random variable can take on finitely many or countably infinitely many values but the outcome of the statistical experiment is not known.   For such discrete random variables $X$, then
$F_X(k)$ will have a finitely or infinitely countable range,
$\Omega_X: \left\{ k_1, k_2, \ldots \right\}$.
\end{df}


We illustrate the difference between countably finite and countably
infinite with two examples:

\begin{itemize}
\item Suppose that the number of working days in a year is 250.   Absences
from work are noted in employees records.   An experiment consists of
randomly drawing a record to see the number of days absent during a
year.   The random variable $X$ can be defined as the number of days
absent, hence $\Omega_X: \left\{ 0,1,2,\ldots,250 \right\}$.  

\item A Geiger counter is connected to a gas tube in order to record the
background radiation count for a selected time interval $[0,t)$ (where
$t$ is fixed).   The random variable $X$ denotes the number of counts
in this time period, and the sample space is $\Omega_X=0,1,2,\ldots,\infty$.
\end{itemize}


$X$ records the event of interest, in either case we could define the
event $X=3$.   We wish to associate a probability with this event,
that is $p[X=3]$.



\subsection{The mass function}

\begin{itemize}
\item The function given by $p(k) = P(X=k)$ for each $k$ within the range of $X$ is called the \emph{probability mass} of $X$
\item A function can serve as the probability mass function of a discrete random variable $X$ if and only if its values $p(k)$ satisfy
\begin{itemize}
\item[(i)] $p(k) \geq 0$ for each value within its domain
\item[(ii)] $\sum_{k \in \Omega} p(k) = 1$ where the summation extends over all values in its domain
\end{itemize}
\end{itemize}



\includegraphics{acrodocs/IntroProb3DiscreteFunctions-pmf}


\subsection{The distribution function}

\begin{itemize}
\item If $X$ is a discrete r.v., the function given by 

\begin{displaymath}
F(X) = P(X \leq x) = \sum_{k \leq x} p(k)\mbox{ for }-\infty < k < \infty
\end{displaymath}
where $p(k)$ is the value of the probability distribution of $X$ at $k$.
\item $F(x)$ is called the \emph{distribution function} or \emph{cumulative distribution} of $X$
\item The values $F(x)$ of the discrete function of a discrete r.v. $X$ satisfy the conditions:
\begin{itemize}
\item $F(-\infty) = 0$ and $F(\infty) = 1$
\item If $a < b$ then $F(a) \leq F(b)$ for any real number $a$ and $b$.
\end{itemize}
\end{itemize}


 
\includegraphics{acrodocs/IntroProb3DiscreteFunctions-cdf}




\begin{itemize}
\item If the range of a random variable $X$ consists of the values $k_{1} < k_{2} < k_{3} < \cdots < k_{n}$ then:
\begin{itemize}
\item $f(k_{1}) = F(k_{1})$
\item $f(k_{i}) = F(k_{i}) - F(k_{i-1})$ for $i=2, \ldots, n$
\end{itemize}
\end{itemize}

(Note here that we are substituting the specific value $k_1$ for $x$ in the general expression $F(x)$)




\subsubsection{An example}

Consider a coin tossing experiment, where $X(H)=1$ and $X(T)=0$.   The distribution function is given by:

\begin{displaymath}
F(x) = \left\{ \begin{array}{ll} 0 & x < 0 \\ 1-\pi & 0  \leq x < 1 \\ 1 & x  \geq 1 \end{array} \right.
\end{displaymath}

We will find out later that this is the distribution function called Bernoulli.   Bernoulli variables can also be defined by Indicator variables:

\begin{displaymath}
I_A(\omega) =\left\{ \begin{array}{lrl} 1 & \mbox{ if } & \omega \in A \\ 0 & \mbox{ if } & \omega \in A^C \end{array} \right.
\end{displaymath}








%\subsubsection{Empirical distribution function}

%The next set of slides will consider various well studied mathematical functions that provide a model for the way random variables behave.   But it is worth noting the existence of an ``empirical distribution function''.  For example, the Human Resources department of a business with 197 employees examined sickness records.   It summarised the length of time each employee was absent as follows:

%\begin{tabular}{lr}
%0 days absence & 100 staff \\
%1 days absence & 80 staff \\
%2 days absence & 10 staff \\
%3 days absence & 2 staff \\
%4 days absence & 0 staff \\
%5 days absence & 5 staff \\
%6 or more days absence & 0 staff
%\end{tabular}

%We have an ``empirical distribution'' that for example suggests \\
%$p[\mbox{Staff taking 2 days absence in 1 year}] = \frac{10}{197}$.   

%We may or may not wish to fit some kind of mathematical model to this, but there are number of applications where we could work with this empirical distribution directly as it is here.   We will not consider the role of the empirical density function any further, and note it here only so that we have met the terminology.

\section{Problems}

Have a look at any of the problems from 1 to 14 of Blitzstein and Hwang Chapter 3



\chapter{Expectation}


\textit{For more information see section 4.1 and 4.2 of Blitzstein and Hwang.}

\section{Expectation for discrete random variables}

We define the \emph{expectation} of a discrete random variable as
follows:

\begin{df}
\begin{displaymath}
E(X) = \sum_{k \in \Omega_X} k\ P(X=k)
\end{displaymath}
\end{df}

It's easiest to explain this with an example:


Consider our coin example from earlier.   We had $\Omega = \{\omega_1, \ldots, \omega_4 \} = \{HH, HT, TH, TT\}$.   We defined the random variable $X(\omega)$ as the number of tails.   Hence, by the na\"ive defintion of probability we want the following pmf:

\begin{tabular}{rrr}
HH & $0$ & $1/4$ \\
HT & $1$ & $1/4$ \\
TH & $1$ & $1/4$ \\
TT & $2$ & $1/4$ 
\end{tabular}

So the p.m.f. $Pr(X=k)$ reduces to 

\begin{displaymath}
P(X=k) = \left\{ \begin{array}{rrr} 1/4 & \mbox{ if } & X=0 \\
1/2 & \mbox{ if } & X=1 \\ 1/4 & \mbox{ if } & X = 2 \end{array} \right.
\end{displaymath}

Now use this to calculate the expected value:

\begin{tabular}{rrr}
$k$ & $p(k)$ & $k \times f(k)$ \\
\hline
$0$ & $1/4$ & $0$ \\
$1$ & $1/2$ & $1/2$ \\
$2$ & $1/4$ & $1/2$ \\
\hline
 & $\sum k\times p(k)$ & $1$
\end{tabular}

So here $E(X)=1$


\subsection{Expectation of a function of a discrete random variable}

Blitzstein refers to this as the Law Of The Unconcious Statistician (LOTUS).   Although this is lovely and simple, it's not obvious why it should be valid.
  Now we need to consider the expected value of a function of $X$, quite often this will be as simple as $g(X) = X^2$.

\begin{df}
$E\big( g(X) \big) = \sum_{k \in \Omega} g(k) Pr[X=k]$
\end{df}




We're not restricted to $g(X)$ being quite so mathematical (in other words, the idea of Expectation comes up in lots of other useful places).


Example. Consider a wedding cake baker.   They believe that the demand for cakes on a daily basis follows a Discrete Uniform distribution between 0 and 5 (i.e. $P(X=0)=P(X=1)= \cdots =P(X=5) = \frac{1}{6}$.   It costs 40GBP to bake a cake, and they make 100GBP when they sell a cake.   What is the expected value of a policy whereby they bake 4 cakes a day?

\begin{tabular}{rrlr}
k    & $P(X=k)$ & $g(k)$ & $g(k)p(k)$ \\ 
\hline
0 & $1/6$ & $4 \times -40 + 0 \times 100$ & $-160/6$ \\
1 & $1/6$ & $4 \times -40 + 100 + 1 \times 100$ & $-120/6$ \\
2 & $1/6$ & $4 \times -40 + 100 + 2 \times 100$ & $40/6$ \\
3 & $1/6$ & $4 \times -40 + 100 + 3 \times 100$ & $140/6$ \\
4 & $1/6$ & $4 \times -40 + 100 + 4 \times 100$ & $240/6$ \\
5 & $1/6$ & $4 \times -40 + 100 + 4 \times 100$ & $240/6$ \\
\hline
$E \big( g(X) \big)$ & $\sum g(k)p(k)$ & & 63.3  
\end{tabular}

(As an extension activity you could see how $E \big( g(X) \big)$ varies if we altered the policy to baking 5 cakes or baking 3 cakes).

\subsection{Summary: Expectation of discrete random variables}

To conclude, our definition of expectation is given as follows:

\begin{df}
The expected value of a discrete random variable ({\color{red} and the expected value of a \emph{function} of a random variable}) as follows:
\begin{itemize}
\item $E(X) = \sum_{k \in \Omega_X} k p(k)$
\item {\color{red}$E\big( g(X) \big) = \sum_{k \in \Omega_X} g(k) p(k)$}
\end{itemize}
\end{df}


\section{Variance}

The variance of a random
variable $X$ is defined as:


\begin{df}
\begin{displaymath}
V (X) = E \big( (X-E[X])^2 \big)
\end{displaymath}
\end{df}

A little bit of algebra also tells us that:

\begin{eqnarray*}
V(X) &=& E \big( (X-E[X])^2 \big) \\
 &=& E\big( (X^2)-2X(E[X]) + (E[X])^2 \big) \\
 &=& E(X^2) - 2(E[X])^2 + (E[X])^2\\
 &=& E(X^2) - \big(E(X)\big)^2
\end{eqnarray*}

which can be a useful thing to know.   This can be illustrated with an example:


\subsection{Some properties of Expectation}


Some properties of expectations are given below; proofs will be given in class.

\begin{eqnarray*}
E(cX) &=& cE(X)\\
E(X + c) &=& E(X) + c\\
E(X+Y) &=& E(X) + E(Y)\\
\end{eqnarray*}

It can be seen for example that the expectation is a nice linear
function (look at the effect of multiplying by or adding a constant).
The same is not true of the variance: 

\begin{eqnarray*}
Var(cX) &=& c^2 Var(X)\\
Var(X+c) &=& Var(X) \\
\end{eqnarray*}

Also, note that $Var(X+Y) = Var(X) + Var(Y)$ iff the two variables are \emph{independent}.


\section{Problems}

\begin{enumerate}
\input{Problems/dummy8/DiscreteExamples_Varx.tex}
\input{Problems/dummy8/Exp_RiggedDie.tex}
\input{Problems/dummy8/Exp_JamesBond.tex}
\input{Problems/dummy8/Exp_Forecourt.tex}
\end{enumerate}


Pick any problems from 1 to 16 from Chapter 4 of Blitzstein and Hwang to make sure you have mastered this topic.


\chapter{Celebrity discrete probability distributions}



\section{Bernoulli trials}

{\color{green}By convention we write $Z \sim Bern(p)$}

\fbox{
\begin{minipage}[c]{1.0\textwidth}
\textbf{Notation alert!}

\begin{itemize}
\item $Z$ is upper case to denote it is a random variable
\item The tilde $\sim$ denotes ``is simulated as''
\item Bern is short for Bernoulli, the name of the distribution
\item $p$ is the parameter.  There are an infinity of Bernoulli distributions, one for each possible value of $p$.
\end{itemize}
\end{minipage}
}


Repeated \emph{independent} trials are called Bernoulli if:
\begin{itemize}
\item There are two possible outcomes (events) conventionally denoted success
  and failure.   More broadly we should think of this as an indicator random variable where:

\begin{displaymath}
Z = \left\{ \begin{array}{rrr} 1 & \mbox{ if } & \mbox{ Event happens} \\ 
0 & & \mbox{Otherwise} \end{array} \right.
\end{displaymath}
\item The probabilities ($P[X=1]=p$ and $P[X=0]=(1-p)=q$) remain the same from trial
  to trial
\end{itemize}

An example of a Bernoulli trial is a coin tossing experiment.   Also,
if we have a stable production process the probability of selecting a
defective item might be Bernoulli.   Can you suggest some other examples?


If we denote the parameter by $p$ where $0 < p < 1$, we have:

\begin{displaymath}
P(Z=k) = \left\{ \begin{array}{rrl} $p$ & & \mbox{ if } Z = 1\\
1-p & & \mbox{ if } Z=0 \\
0 & & \mbox{ otherwise}
\end{array} \right.
\end{displaymath}

We can simply check that $\sum_{k=0}^1 Pr[X=k] = 1$ as we have $p + (1-p)=1$.

The mean of $Z$ i.e. $E(Z)$ is found as: 
\begin{displaymath}
1 \times p + 0 \times (1-p) = p
\end{displaymath}

To find the variance, we first need 
\begin{displaymath}
E(Z^2) = 1^2 \times p + 0^2 \times 1-p = p
\end{displaymath}, so 

\begin{displaymath}
V(Z) = E(Z^2)-E(Z)^2 = p - p^2 = p(1 - p).
\end{displaymath}


\subsection{Indicator random variables}

Note that the probability that an event $A$ happens, i.e. $P(A)=p$ is the same as the expectation $E[Z]$.

So note that in this indicator variable example we have a link where:

\begin{displaymath}
E(Z) = P(A)
\end{displaymath}

Demonstrating a close relationship between expectation and probability.

\section{Binomial distribution}

{\color{green}By convention we write $X \sim B(n, p)$}


Suppose we have a sequence of $n$ Bernoulli trials, with Bernoulli
random variables $Z_1, Z_2, \ldots, Z_n$ (all taking on values 1 or
0).   The random variable $X=Z_1 + Z_2 + \ldots + Z_n$ essentially
denotes the number of \emph{successes} amongst the $n$ Bernoulli
trials.

We could alternatively just think of it as the number of \emph{successes} in $n$ trials and forget the Bernoulli story.

This value has a formula as follows:

\begin{displaymath}
f(k) = p[X=k] = \left\{  \begin{array}{crr}  {n \choose k} p^k (1-p)^{n-k} & &  \mbox{ for }
k=0,1,2,\ldots,n \\
0 & & \mbox{ otherwise.} \end{array} \right.
\end{displaymath}


Let's think a little about why.   Assuming that $P[Success]=p$ and $P[Failure] = (1-p) = q$, consider the probability of the following event:

\begin{tabular}{rrrrrr}
F & S & F & F & S & S \\
q & p & q & q & p & p \\
\end{tabular}

As the individual events are independent, we can just multiply the probabilities and so we have $q \times p \times q \times q \times p \times p = p^3q^3$.   Or if we said we had $n$ trials and $k$ successes, with $n-k$ failures we have $p^k  q^{(n-k)}$.

The only problem here is that this is the probability of getting that particular ordering of Failures and Successes.   We could have obtained 3 successes from (S, S, S, F, F, F), or a number of other orderings.   How many orderings.   We did that already, it's $\binom{n}{k}$.   So, the probability of getting $k$ successes in $n$ trials is going to be:

\begin{displaymath}
P[X=k] = \binom{n}{k}p^k q^{n-k}
\end{displaymath}
as required.



We can check that this is non-negative.   What about summing to one.   Well:

\begin{displaymath}
\sum_{k=0}^n \binom{n}{k} p^k q^{n-k} = (p+q)^n
\end{displaymath}
by the Binomial theorem.  And for this particular problem, we know that $(p+q)=1$, so it is a pmf which obeys the second Kolmogorov Axiom.


Find $E(X)$ the hard way:

\begin{displaymath}
E(X) = \sum_{k=0}^n k \binom{n}{k} p^k q^{n-k}
\end{displaymath}

The first term is $0$ at $k=0$ so start the summation at $k=1$ and use Committee Chairman trick to change the permutation counter:

\begin{displaymath}
E(X) = \sum_{k=1}^n  n \binom{n-1}{k-1} p^k q^{n-k} 
\end{displaymath}

Now take that $n$ (and one $p$) outside the summation

\begin{displaymath}
E(X) = np \sum_{k=1}^n   \binom{n-1}{k-1} p^{k-1}q^{n-k}
\end{displaymath}

Now just let $j=k-1$ (and $m=n-1$ if you worry about that sort of thing.   The term on the right becomes $1$ so we have
\begin{displaymath}
E(X) = np
\end{displaymath}



Find $E(X)$ the easy way.

We said it's the sum of $n$ iid Bernoulli r.v.s.   So by linearity:
\begin{displaymath}
E[X] = E[Z_1 + Z_2 + \cdots + Z_n] = E[Z_1] + E[Z_2] + \cdots + E[Z_n]
\end{displaymath}
We said before $E[Z] = p$, so this is just $np$.   We can find $E[X^2]$ in the same way and hence confirm:

\fbox{For $X \sim Binomial(n,p)$: $E(X) = np$ and $V(X)=npq$.}


Nowadays, it is pretty straightforward to compute these values, but
once upon a time it was conventional to work with tables of
probabilities.  
\begin{figure}
\includegraphics{acrodocs/IntroProb3cDiscreteExamples-bin}
\end{figure}

\clearpage

\subsection{The Geometric Distribution}

{\color{green} By convention we write $X \sim Go(p)$} 

We shall briefly consider the scenario whereby successive Bernoulli trials are continued until the first success occurs.   Let $X$ denote the number of trials up to but not including the first success.   This gives rise to what we call the Geometric distribution.   

\begin{df}
For data assumed to follow the Geometric distribution, $X$ has a probability density function:
\begin{displaymath}
P(X=k) = p(k) =  \left\{ \begin{array}{crr} (1-p)^{k}p; & & \mbox{ for } k=0,1,2,\ldots\\
0 & & \mbox{ otherwise } \end{array} \right.
\end{displaymath}
for $0 < p < 1$.
\end{df}



It is quite simple to derive this pmf.   We have (for example):
\begin{tabular}{rrrrr}
F & F & F & F & S \\
$q$ & $q$ & $q$ & $q$ & $p$
\end{tabular}

There is clearly only one way in which we can obtain this set of events.

It is clearly non-negative, to check it sums to one we need:

\begin{displaymath}
\sum_{k=0}^{\infty} pq^{k} = p \sum_{k=0}^{\infty} q^{k}
\end{displaymath}
That term to the right of the $p$ on the right hand side is a standard geometric series which we can write also as $\frac{1}{1-q}$.   So we have 


\begin{displaymath}
\sum_{k=0}^{\infty} pq^k = \frac{p}{1-q} = \frac{p}{p} = 1
\end{displaymath}


A little more work is needed to obtain the expectation.

\begin{displaymath}
E(X) = \sum_{k=0}^{\infty} k p q^k =  p \sum_{k=1}^{\infty} k q^k
\end{displaymath}

Note the trick of removing $k=0$ as the sequence is zero at that point.   This looks a little, but not entirely like a geometric series.   Let's do some maninpulation.  On line 2 we have differentiated both sides, on row three we have multiplied both sides by $a$:

\begin{eqnarray*}
\sum_{b=0}^{\infty} a^b &=& \frac{1}{1-a} \\
\sum_{b=0}^{\infty} b a^{b-1} &=& \frac{1}{(1-a)^2} \\
\sum_{b=0}^{\infty} b a^{b} &=& \frac{a}{(1-a)^2} \\
\end{eqnarray*}

So this gives us the expression we need.

\begin{displaymath}
 E(X) = p \sum_{k=1}^{\infty} k q^k = p \frac{q}{(1-q)^2} = \frac{pq}{p^2} = \frac{q}{p}
\end{displaymath}


For example, a burglar want to know that he will get away with three ``jobs'' before he finally gets caught.  Assuming the probability of being caught (a success for the rest of us) is $p=0.6$ we have $p[X=3]=(1-0.6)^30.6=0.0384$


\subsection{Alterantive definition}
  

Note carefully.   You can also define the Geometric random variable as the number number of trials, \emph{up to and including} the first success.   In that case we have:

\begin{displaymath}
P(X=k) = q^{k-1}p
\end{displaymath}


For example, if a salesperson wishes to calculate the probability that they will make their first successful sale of the day to the fifth customer, given that the probability of a sale $p=0.2$ is given by $P(X=5)=(1-0.2)^{5-1}0.2 = 0.08192$


\fbox{Note in this latter case that $E(X) = \frac{1}{p}$ and $V(X)=\frac{1-p}{p^2}$.}






%\section{The negative binomial distribution}

%{\color{green}By convention we would write $X \sim NB(r,p)$}

%If we extend the previous idea so that we can continue the Bernoulli trials until the $r$th success, and denote $X$ as the number of such trials required, then $X$ has a negative binomial distribution.


%\begin{df}
%The negative binomial distribution, with parameter $p; 0 < p < 1$ and size $n=1,\dots \infty$ is given by:
%\begin{displaymath}
%P(X=k) = \left\{ \begin{array}{crr} {k-1 \choose r-1} \pi^r (1-\pi)^{k-r} & & \mbox{ for } k = 0,1, \ldots N \\ 0 & & \mbox{ otherwise.} \end{array} \right.
%\end{displaymath}
%\end{df}

%\fbox{  Note that $E(X)=\frac{r}{p}$ and $V(X)=\frac{r(1-p)}{p^2}$}



%Consider a country where the prime minister has an interesting private life   The probability that a person believes a rumour about this prime minister is $p=0.25$.  


%\begin{itemize} 
%\item What are the probabilities that the sixth person to hear the rumour will be the sixth to believe it: $p(X=6|n=6,p=0.25) = {(6-1) \choose (6-1)} 0.25^6 (1-0.25)^{6-6}$ which should equal $0.00024$
%\item What is the probability that the twelfth person to hear the rumour will be the fourth to believe it: $p(X=4|n=12,p=0.25) = {(12-1) \choose (4-1)} 0.25^4 (1-0.25)^{12-4}$ which should equal $0.065$
%\end{itemize}


\section{The Hypergeometric distribution}

This isn't what happens to a geometric distribution if you give it too many sugary sweets and fizzy drinks.   A random variable $X$ is said to follow the hypergeometric distribution if its probability mass function (pmf) is given by:

$$P(X=k) = {{{K \choose k} {{N-K} \choose {n-k}}}\over {N \choose n}}$$

Where:
\begin{itemize}
\item    $N$ is the population size
\item $K$ is the number of "successes" in the population
\item $n$ is the sample size
\item $k$ is the number of successes in the sample.
\end{itemize}
Do note that ${a \choose b}$ is a binomial coefficient for integers $a$ and $b$.


Showing that this is a valid p.m.f. - see tutorial sheets (or look up the Vandermonde identity to see that the sum of the numerator over all possibilities equals the denominator).




\section{The Poisson distribution}

{\color{green}By convention we would write $X \sim P(\lambda)$} 

The Poisson distribution is used to model events occurring at random in time, area, volume.

\begin{df}
The Poisson distribution, with parameter $\lambda: \left\{0 \leq \lambda \leq \infty \right\}$ is given as follows:
\begin{displaymath}
P(X=k) = \left\{ \begin{array}{crr} \frac{\lambda^k e^{-\lambda}}{k!}; & & \mbox{ if } k=0,1,2,\ldots; \\ 0 & & \mbox{otherwise.} \end{array} \right.
\end{displaymath}
\end{df}



You can check it's non-negative.   What about summing to one:

\begin{displaymath}
\sum_{k=0}^{\infty} \frac{e^{-\lambda}\lambda^k}{k!} = e^{-\lambda} \sum_{k=0}^{\infty} \frac{\lambda^k}{k!}
\end{displaymath}

You should check that the right hand part here is the Taylor series for $e^{\lambda}$ so we have
\begin{displaymath}
\sum_{k=0}^{\infty} \frac{e^{-\lambda}\lambda^k}{k!} = e^{-\lambda}e^{\lambda} = 1
\end{displaymath}



A little bit more work is needed to find the expecation.

\begin{displaymath}
E(X) = \sum_{k=0}^{\infty} k \frac{e^{-\lambda}\lambda^k}{k!} = e^{-\lambda} \sum_{k=0}^{\infty} k \frac{\lambda^k}{k!}
\end{displaymath}

We can repeat our trick of starting the summation from $k=1$, and note that in $\frac{k}{k!}$ we can cancel one $k$ giving us $\frac{1}{(k-1)!}$

\begin{displaymath}
E(X)  = e^{-\lambda} \sum_{k=1}^{\infty}  \frac{\lambda^k}{(k-1)!}
\end{displaymath}

We can also bring one $\lambda$ into the front of the sum

\begin{displaymath}
E(X)  = \lambda e^{-\lambda} \sum_{k=1}^{\infty}  \frac{\lambda^{(k-1)}}{(k-1)!}
\end{displaymath}

We can now do some change-of-variables: $j=k-1$ but you should be able to see where this is going.   The rightmost term is our Taylor series for $e^{\lambda}$ again.   So that:

\begin{displaymath}
E(X) = \lambda e^{-\lambda} e^{\lambda} = \lambda
\end{displaymath} 

We will though find a much simpler way to get $Var(X)$




\fbox{Summary: $E(X)=\lambda$ and $V(X)=\lambda$.}


Example. The number of accidents on the Pasadena Freeway between 9am and 10am on a Sunday morning is a random variable, thought to follow a Poisson distribution with $\lambda = 7.3$.   Find the probability that there will be:

\begin{itemize}
\item Exactly 6 accidents.\\ For this we need to find $P(X=6|\lambda=7.3)$ which is given by $ \frac{7.3^6e^{-7.3}}{6!} = 0.1420$
\item Less than 4 accidents.\\ For this we need the distribution which is given by  $P(X < 4 |\lambda=7.3)$.   We find this by taking the following\\ $ P(X =0 |\lambda=7.3) + P(X = 1 |\lambda=7.3) + P(X =2  |\lambda=7.3) + P(X =3|\lambda=7.3)$.   This is given by calculating\\ $\frac{7.3^0e^{-7.3}}{0!} + \frac{7.3^1e^{-7.3}}{1!} + \frac{7.3^2e^{-7.3}}{2!} + \frac{7.3^3e^{-7.3}}{3!}$ which should give $0.0674$
\end{itemize}





These are the most important examples of discrete probability functions (although there are hundreds available).   It is worth being familiar with the key properties of these densities.



\section{Problems}

\begin{enumerate}
\input{Problems/dummy9/DiscreteExamples_Asthma.tex}
\input{Problems/dummy9/DiscreteExamples_Cookies.tex}
\input{Problems/dummy9/DiscreteExamples_RoadAccidents.tex}
\input{Problems/dummy9/DiscreteExamples_HouseRepairs.tex}
\input{Problems/dummy9/DiscreteExamples_GAM.tex}
\input{Problems/dummy9/DiscreteExamples_GAM2.tex}
\input{Problems/dummy9/DiscreteExamples_DiceRollingTillSuccess.tex}
\input{Problems/dummy9/DiscreteExamples_StudentCallout.tex}
\input{Problems/dummy9/DiscreteExamples_LogarithmicConstant.tex}
\input{Problems/dummy9/DiscreteExamples_LogarithmicEX.tex}
\input{Problems/dummy9/DiscreteExamples_LogarithmicVar.tex}
\input{Problems/dummy9/DiscreteExamples_LogarithmicCDF.tex}
\end{enumerate}


For further practice pick any problems from 15 to 37, 45 to 47 (chapter 3) and 17 to 29, 56 to 67, 73 to 83 (chapter 4) in Blitzstein and Hwang.   The exam doesn't necessarily have to concentrate on Celebrity Distributions that we have studied in detail in class.   You need to know how to verify a function is a valid PMF and find it's expectation and variance.


\chapter{Continuous Probability Functions}

See chapter 5 of Blitzstein and Hwang.

%\section*{Aims}
%\begin{itemize}
%\item To state some key properties of continuous random variables
%\item To examine some important continuous distributions
%\item To become comfortable solving problems involving the normal distribution
%\end{itemize}


\section{Continuous r.v.s}

Further information is given in Section 5.2 (page 205) of Grinstead and Snell.

\subsection{Probability density function}

\begin{itemize}
\item A function with values $f(x)$ defined over the set of all real numbers, is called a \emph{probability density function} of the continuous random variable $X$ if and only if $P(a \leq X \leq b) = \int_{a}^{b} f(x) dx$ for any real constants $a$ and $b$ with $a < b$
\item Note that if $X$ is a continuous random variable and $a$ and $b$ are real constants ith $a \leq b$ then $P(a \leq X \leq b) = P(a \leq X < b) = P(a < X \leq b) = P(a < X < b)$
\end{itemize}
i.e. the value of a pdf can be changed for some of the values on an r.v. without changing the probabilities.


Some points about this definition:
\begin{itemize}
\item For discrete random variables, the probability mass function is easy to understand: $p(x) = P(X=x)$.
\item But note the terminology, if probability is mass, what is density?
\item For a continuous random variable, $P(X=x)=0$
\item But if we think of density as mass per volume, perhaps we gain a few insights
\item Maybe try thinking about a tiny number $\epsilon$.  Then think about $\int_{x-(\epsilon/2)}^{x+(\epsilon/2)} f(t)dt$.   If $\epsilon$ is small enough then we have a rectangle of area $\epsilon \times f(x)$; this area is the probability.
\end{itemize}






 \begin{itemize}
\item A function can serve as a probability density function of a continuous r.v. $X$ if its values $f(x) $ satisfy the conditions:
\begin{itemize}
\item $f(x) \geq 0$ for $-\infty < x < \infty$
\item $\int_{-\infty}^{\infty} f(x) dx = 1$
\end{itemize}
\end{itemize}

\subsection{Cumulative distribution function}

\begin{itemize}
\item If $X$ is a continuous r.v. and the value of its probability density at $t$ is $f(t)$, then the function given by $F(x) = P(X \leq x) = \int_{-\infty}^{x} dt$ for $-\infty < x < \infty$ is called the \emph{distribution function} or cumulative distribution of $X$
\item If $f(x)$ and $F(x)$ are values of the probability density and distribution function of $X$ at $x$ then $P(a \leq X \leq b) = F(b) - F(a)$ for any real constants $a$ and $b$ with $a \leq b$ and $f(x) = \frac{dF(x)}{dx}$ where the derivative exists
\end{itemize}
 



Give the fundamental theorem of calculus, it is perhaps no surprise that if

\begin{displaymath}
F(x) = \int_{-\infty}^x f(t)dt
\end{displaymath}

Then

\begin{displaymath}
f(x) = \frac{dF(x)}{dx} = F'(x)
\end{displaymath}





\subsection{Computer illustration}

Nowadays, it is trivial to use a computer to randomly generate some continuous variables (although strictly we should note that computers can only generate \emph{pseudo} random numbers, but for our purposes this is close enough).  

\begin{itemize}
\item  For the moment we will not concern ourselves with the density used to create these variables, 
\item Instead, we will consider only the empirical density.   
\item In other words, for a sample of size $n$, the probability of observing any particular value will be $\frac{1}{n}$.   
\end{itemize}

We can generate a range of sample sizes (25, 100, 1000, 10000), observe both the value of $x$ and the empirical density for that value, and plot these as a set of lines.   The position on the x-axis denotes the value of $x$, the height of the line denotes the empirical density for observing that variable.

\begin{itemize}
\item Look very carefully at each of the four plots, noting that the scaling of the $y$ axis changes.
\item What will happen to the height of these lines when, instead of using the empirical density, we use a continuous density function that must allow for an infinite range of possible values of $x$?
\end{itemize}


\includegraphics{acrodocs/IntroProb4Continuous-discreteprob}





What is also apparent is that these plots are not use if we wish to visualise set containing a large number of realisations of $x$.   When $n$ is too large, we have a large pool of black ink in the middle of the charts.  

\begin{itemize}
\item The conventional way of dealing with this is by means of a histogram
\item We break the x-axis into ``bins'' (a range of values) and count the number of values in that range
\item The area of a given bar therefore tells us something about the probability density.   
\item Note that as the sample size increases (and I have used narrower and narrower bins), we see a clear shape emerging.
\end{itemize}
All we need to do know is to define some mathematical formula that can adequately describe this, or any other shape, as necessary.


\includegraphics{acrodocs/IntroProb4Continuous-hist}




\subsection{Expectation}

Where we used the summation operator for discrete densities, for a continuous random variable we define expectation using the integration operator.   This follows from the standard mathematical definition for
the ``average'' of a function.

\begin{df}
The expected value of a continuous random variable is given by:
\begin{displaymath}
E(X) = \int_{-\infty}^{\infty} x f(x) dx
\end{displaymath}

and the expected value of a \emph{function of} a random variable $g(X)$ is given by:
\begin{displaymath}
E \big( g(X) \big) = \int_{-\infty}^{\infty}  g(x) f(x) dx
\end{displaymath}
\end{df}




\subsection{Variance}

The Variance of a continuous density is defined in exactly the same way as for discrete random variables i.e. $V(X) = E \big( X-E(X) \big)^2$.   
%We shall revisit this point next week when we consider \emph{moments}.


\subsection{Anatomy of a pdf}

We only need a non-negative function that integrates to $1$ over it's domain.   Hence we need something that takes the form:

\begin{displaymath}
f(x) = c h(x)
\end{displaymath}
where $c$ is known as the constant of integration, and $h(x)$ describes a useful shape.   Clearly $c=\frac{1}{\int h(x) dx}$

Example.   You have a random variable $X$ such that $0 < X < 3$.   You decide to use $f(x) = c x^2$ as your pdf.   Find $c$.

You need to find

\begin{displaymath}
\int_0^{3} x^2 dx = 9
\end{displaymath}

So 

\begin{displaymath}
f(x)= \left\{ \begin{array}{ccc} \frac{1}{6} x^2 & & \mbox{ for } 0 < x < 3 \\
0 & & \mbox{ otherwise } \end{array} \right.
\end{displaymath}

forms a pdf for this $X$.



\subsection{Summary}

\begin{tabular}{rll}
What & $X$ Discrete & $X$ continuous \\
\hline
pmf: &    $p(k) =P(X=k)$ & Not defined \\
pdf: & Not defined &  $f(x)$ s.t. $P[a<X<b]=\int_a^b f(x)dx$\\
cdf:  & $F(x) = P(X \leq x) = \sum_{-\infty}^x f(t)$ & cdf: $F(x) = P(X \leq x) = \int_{-\infty}^x f(t)dt$\\
Expectation & $E[X] = \sum_x x p(x)$ & $E[X] = \int_x x f(x) dx$\\
Expect of a fn & $E \big( [g(X) \big) = \sum_x g(x) f(x)$ & $E \big( g(X) \big) = \int_x f(x) f(x) dx$\\
\end{tabular}

This last fact lets us find $Var(X)$ in either case.





\section{The uniform distribution}

{\color{green}By convention we write $X \sim U(a, b)$}


The random variable $X$ has a uniform distribution if its probability density function is constant over the range defined by $a$ and $b$.   For example, the following is meant to show $x$ in the middle of the range: $a---x---b$, we would expect $P[X<x]=P[X>x]$.   Now imagine $a--x----b$.  Here we would expect $P[X<x] =  \frac{1}{2}P[X>x]$ (because the first interval is meant to be half the length of the second interval).   Maybe it helps to think of probability as proportional to length.

Basically, this means we want:

\begin{displaymath}
f(x) = \left\{ \begin{array}{rrr} c & \mbox{ if } & a \leq x \leq b\\
0 & & \mbox{otherwise} \end{array} \right.
\end{displaymath}

If we want this to obey $P(\Omega)=1$ we need $\int_a^bc=1$ which gives us $\frac{1}{b-a}$

The cumulative distribution function therefore is given as follows:

\begin{displaymath}
F(x|a,b) = \left\{ \begin{array}{ll} 0 & \mbox{ for }  x \leq a \\
\frac{x-a}{b-a} & \mbox{ for } a \leq x \leq b \\ 
0 & \mbox{ for } x > b \end{array} \right. 
\end{displaymath}


\subsection{The Standard Uniform Distribution}

One important example is the ``standard'' uniform, i.e. where $U \sim U(0,1)$ (the building block of all other random numbers):


\begin{displaymath}
E(X) = \int_0^1 x \times\frac{1}{1-0} = \frac{x^2}{2}|^1_0=\frac{1-0}{2}
\end{displaymath}

So for $U \sim Unif(0,1)$ this gives us $E(X) = \frac{1}{2}$

For $E[X^2]$ we get $\frac{x^3}{3} \times 1 |^1_0$ which for which yields $\frac{1}{3}$  Therefore, using $Var(X)=E(X^2)-E(X)^2$ we have $Var(X)=\frac{1}{3}-\frac{1}{4}=\frac{1}{12}$


\fbox{Summary: for the standard uniform $E(U) = \frac{1}{2}$ and $V(U)=\frac{1}{12}$.}

\subsection{The non-standard Uniform}

We can attack this directly.   For $W \sim Unif(a,b)$ we have that:

\begin{displaymath}
E(X) = \int_a^b x \frac{1}{b-a} = \frac{x^2}{2}b-a|^b_a=\frac{a+b}{2}
\end{displaymath}

For $E(X^2)$ we get $\frac{x^3}{3}(b-a)|^b_a$ which yeilds $\frac{1}{3}\frac{B^3-a^3}{b-1} - \left(\frac{a+b}{2}^2\right)$ which (eventually) simplifies to $Var(W)=\frac{(b-a)^2}{2}$


\fbox{Summary: for $a=0$ and $b=1$ that $E(X) = \frac{a+b}{2}$ and $V(X)=\frac{(b-a)^2}{12}$.}


\subsection{Using a location scale transformation}

For (almost) any Random Variable $Y$ we can define it as  a linear transformation of Random Variable $X$ in terms of two constants $c$ and $d$ so that

\begin{displaymath}
Y = cX + d
\end{displaymath}

Using standard rules of expectation, clearly 

\begin{displaymath}
E(Y) = E( cX + d) = cE(X) + d\\
\end{displaymath}

and 

\begin{displaymath}
V(Y) = V(cX+d) = c^2 V(X)
\end{displaymath}


So, let $U$ be a random variable and $W=cU + d$.   As we will explain in class, in the case of the Uniform, $c$ is equivalent to $b-a$ and $d$ is equivalent to $a$.


\begin{displaymath}
E(W) = E \big( (b-a) U + a \big) =  \frac{1}{2}(b-a) + a = \frac{a+b}{2}
\end{displaymath}

Likewise for the variance

\begin{displaymath}
V(W) = V \big( (b-a) U + a \big) =  (b-a)^2 V(U) = (b-a)^2 \frac{1}{12} + a = \frac{(b-a)^2}{12}
\end{displaymath}


As we will find out, where we can use them, this kind of transformation is a very powerful technique.


\subsection{The negative exponential distribution}

{\color{green} By convention we write $X \sim NE(\lambda)$}

\begin{displaymath}
f(x|\lambda) = \left\{ \begin{array}{rrr} \  \lambda e^{-\lambda x} & & \mbox{ for } x>0 \\ 0 & & \mbox{ elsewhere } \end{array} \right.
\end{displaymath}
for any value of $\lambda>0$.

(In passing please note that conventionally in text books this will be written as $f(x)=\lambda e^{-\lambda x}; x>0, \lambda>0$ telling you both the domain of the family of functions as well as all the parameter values for which this function is defined.)

It should be obvious that this is non-negative and $\int_0^{\infty}f(x)dx=1$

Here, we have a distribution function expressed as:
\begin{displaymath}
F(x|\lambda) = 1-e^{-\lambda x}
\end{displaymath}

%One feature here is that this density is only defined for non-negative values of $x$.   This distribution is commonly used as a simple model for time between events; and a little thought is required here.   For example, if the count of events that happens in a given time period $Y \sim P(\theta)$ and the waiting time between those events is $X \sim NE(\theta)$ it should come as no surprise that $\theta$ and $\theta$ are related ($\theta = \frac{1}{\theta}$


\subsection{The Standard Exponential}

We can define a standard Exponential, i.e., $Y=\lambda X$ where $Y \sim Exp(1)$.

\begin{displaymath}
f(y) = \left\{ \begin{array}{rrr} \   e^{- y} & & \mbox{ for } y>0 \\ 0  & & \mbox{ elsewhere } \end{array} \right.
\end{displaymath}


For this, we can then find $(Y)$:

\begin{displaymath}
E(Y) = \int_{0}^{\infty} y e^{-y}dy
\end{displaymath}

Now use use integration by parts: $\int u\ dv = uv - \int v\ du$ such that:
\begin{itemize}
\item[] $u=y \therefore du=dy$
\item[] $dv=e^{-y} \therefore v=-e^{-y}$
\end{itemize}

\begin{displaymath}
\int_{0}^{\infty} y e^{-y}dy = \underbrace{-ye^{-y}|^{\infty}_o}_{0} - -\underbrace{\int_0^{\infty} e^{-y}dy}_{1} = 1
\end{displaymath}

Similarly, we can find $E(Y^2)=2$   Hence $Var(Y) = 2-1^2=1$


\subsection{The non-standard exponential}

We now need to rescale our standard exponential, noting that $X=\frac{Y}{\lambda}$, so $E[X] = \frac{1}{\lambda}$ and $Var(X)=\frac{1}{\lambda^2}$

(As an exercise you might like to check you can find $E[X]$ and $V(X)$ for the non-standard exponential directly).

\fbox{Note that $E(X) = \frac{1}{\lambda}$, $Var(X)=\frac{1}{\lambda^2}$}

%\fbox{Also note it is possible to use the parameterisation $f(x) = \frac{1}{\lambda} e^{-\frac{1}{\lambda} x}$}


\subsubsection{Memoryless}

A vital property of the Exponential distribution is that:

\begin{displaymath}
P[X \geq a+b | X \geq a] = P[X \geq b]
\end{displaymath}

Proof.

Firstly, let's find the so-called survivor function:

\begin{eqnarray*}
P[X \geq a] &=& 1-F(a)\\ 
&=& 1 - (1-e^{\lambda a}) \\
&=& e^{\lambda a}
\end{eqnarray*}


Now let's use basic conditional probability:

\begin{displaymath}
P[A|B] = \frac{P[A \cap B]}{P[B]}
\end{displaymath}

%But if $A$,$B$ are independent, then $P[A \cap B] = P[A,B]$

\begin{eqnarray*}
P[X \geq a+b | X \geq a] &=& \frac{P[X \geq a+b, X \geq a]}{P[X \geq b]}\\
&=& \frac{e^{-\lambda(a+b)}}{e^{-\lambda b}} = e^{-\lambda a}
\end{eqnarray*}

%Side note (more on conditional expectation to follow):

%\begin{displaymath}
%E[X|X>a] = a + E[X-a|X+a]=a+\frac{1}{\lambda}
%\end{displaymath}



Memoryless can be great in some applications (failure times of lightbulbs) but not in others (life expectancy).




\section{The Gamma distribution}

{\color{green} By convention we write $Y \sim Gamma(a,\theta)$}

By way of introduction, recall the Gamma function:
\begin{displaymath}
\Gamma (a) = \int_0^{\infty} x^{a-1} e^{-x} dx
\end{displaymath}

If we want to use this as a pdf (for random variable $X$ and parameter $a$, we need to make it integrate to one.   How?   The clue should be in the resursive nature of the Gamma function.   Let's divide it by itself!

\begin{displaymath}
f(x) =  \left\{ \begin{array}{rrr} \frac{1}{\Gamma (a)} x^{a-1} e^{-x} dx & & \mbox{ for } x>0 \\ 0 & & \mbox{ otherwise } \end{array} \right.
\end{displaymath}
for $a>0$.

We can check this is non-negative, and we know $P(\Omega)=1$ because we just made it so.





Because of the recursive properties of the $Gamma$ function, it will turn out to be worryingly easy to find moments.   Taking a ``standard'' Gamma density (i.e., with $\theta=1$:

\begin{eqnarray*}
E(X^c) &=&  \int_0^{\infty} x^c \frac{1}{\Gamma (a)} x^{a-1} e^{-x} dx \\
&=& \frac{1}{\Gamma (a)} \underbrace{\int_0^{\infty}  x^{a+c-1} e^{-x} dx}_{\mbox{A }\Gamma \mbox{ function}} \\
&=& \frac{\Gamma(a+c)}{\Gamma(a)}
\end{eqnarray*}

Hence we can find $E(X^n)$ very simply:

\begin{displaymath}
E(X) = \frac{\Gamma (a+1)}{\Gamma(a)} = \frac{a \Gamma(a)}{\Gamma(a)} = a
\end{displaymath}


\begin{displaymath}
E(X^2) = \frac{\Gamma (a+2)}{\Gamma(a)} = \frac{a+1 \Gamma(a+1)}{\Gamma(a)} = \frac{(a+1)a\Gamma(a)}{\Gamma(a)}  = a^2+a
\end{displaymath}

So $Var(X) = a^2+a-a^2 = a$



\subsection{The Non-Standard Gamma distribution}


At the moment, this has only one parameter.   We can add another by rescaling, such that we then have $Y \sim Gamma(a,\lambda)$ where $Y = \frac{X}{\lambda}$:

\begin{displaymath}
f(y) = \left\{ \begin{array}{rrr} \frac{\lambda^a}{\Gamma (a)} x^{a-1} e^{-\lambda x} &  &\mbox{ for } x>0 \\ 0 & & \mbox{ otherwise } \end{array} \right.
\end{displaymath}
for $a>0$ and $\lambda>0$.
%Do I need \theta^a?????????????

This can be thought of as a nice extension to the negative exponential.  There are two parameters, hence there is more flexibility in defining the sahpe than you have with the negative exponential distribution.   If you restrict $a$ to being an integer, you can think of the $Gamma(a, \lambda)$ as the time taken to the arrival of the $a$th independent $Exponential(\lambda)$ random variables (but $a$ isn't restricted to the integers.   One word of warning, there are two very different ways of specifying the density!  % Here's one:

%\begin{displaymath}
%f(x|a,b) = \frac{a^bx^{b-1}e^{-ax}}{\Gamma(b)}; 0 \leq x < \infty.
%\end{displaymath}

%It might be worth pointing out that $\frac{a^b}{\Gamma(b)}$ is a constant of integration here, the shape and scale is determined by $x^{b-1}e^{-ax}$




Remember that $Y = \frac{X}{\lambda}$

\fbox{Rescaling gives us $E(Y) = \frac{a}{\lambda}$ and $Var(Y) = \frac{a}{\lambda^2}$}


%\fbox{Note that $E[X] = \frac{b}{a}$ and $V[X] = \frac{b}{a^2}$}



%\section{The Cauchy distribution}

%(first considered by Poisson)

%\begin{displaymath}
%f(x) = \frac{1}{\pi (1+x^2)}, -\infty < x < \infty.
%\end{displaymath}

%The most interesting feature of this density is that it has no moments (which we examine next week), and it's most common use is in ``counter examples'' (or trick questions).



\section{The Beta distribution}

{\color{green} By convention we write $X \sim Beta(a,b)$}

\begin{displaymath}
f(x|a,b) = \left\{ \begin{array}{rrr} \frac{\Gamma(a + b)}{\Gamma(a)\Gamma(b)} x^{a-1}(1-x)^{b-1};0 \leq x \leq 1 & & \mbox{ for } 0 < x < 1 \\ 0 & & \mbox{ otherwise} \end{array} \right.
\end{displaymath}
for $a>0$ and $b>0$.

The expression $\frac{\Gamma(a + b)}{\Gamma(a)\Gamma(b)}$ might look intimidating, but it is only a \emph{constant} to make sure that $\int f(x)=1$ for this distribution (it's the reciprocal of the Beta function, so you can guess where this distributio gets its name).   In other words, all the important work in terms of the shape of of the curve is done by $ x^{a-1}(1-x)^{b-1}$; but we need to multiply it by some constant to get the integral over the whole domain equal to one.

It turns out that the uniform distribution is just an example of a beta distribution where $a=1$ and $b=1$.




Finding $E(X^n)$ is easy like the $Gamma$

\begin{eqnarray*}
E(X^n) &=& \frac{1}{Beta(a,b)} \int_{0}^1 x^n x^{(a-1)}(1-x)^{(b-1)}dx \\
&=&  \frac{1}{Beta(a,b)} \int_{0}^1 \underbrace{x^{(a+n-1)}(1-x)^{(b-1)}dx}_{\mbox{A } Beta \mbox{ density}} 
\end{eqnarray*}

So, we know that:

\begin{displaymath}
E(X^n) = \frac{Beta(a-n, b)}{Beta(a,b)} = \frac{\Gamma(a+n) \Gamma(a+b)}{\Gamma(a+b+n)}{\Gamma(a)}
\end{displaymath}

So that:



\fbox{Note that $E(X) = \frac{a}{a+b}$ and $V(X) = \frac{ab}{(a+b)^2(a + b + 1)}$}

(check these: for $a=b=1$ does it match the standard Uniform as promised?




\section{The Normal distribution}

{\color{green}By convention we write $X \sim N(\mu, \sigma^2)$}

This is sometimes named the Gaussian distribution, after Karl Friedrich Gauss who studied some of its key properties.

\begin{df}
The normal density is given by:
\begin{displaymath}
f(x|\mu, \sigma^2)=\frac{1}{\sqrt 2 \pi \sigma} \exp \left\{ -\frac{1}{2} \left(\frac{x-\mu}{\sigma} \right)^2 \right\}, -\infty < x < \infty, \sigma > 0 
\end{displaymath}
for $-\infty < \mu < \infty$ and $\sigma>0$.
\end{df}

There's no easy way of working with the integral (there is no expression for an indefinite integral) so for our purposes we have to assume that with such a well used density someone somewhere has checked that $\int_{-\infty}^{\infty}f(x)=1$.  Again, it might be interesting to know that $=\frac{1}{\sqrt 2 \pi \sigma}$ is another of these constants that ensures the integation is equal to unity.


\fbox{Note that $E(X) = \mu$ and $V(X)=\sigma^2$.}





A nice property of the normal density is that linear functions of a random variable $X$ distributed according the normal distribution will also be normal.

\begin{df}
Let $X \sim N(\mu, \sigma^2)$, and let $Y=\alpha + \beta X$.   Then we have:
\begin{displaymath}
Y \sim N(\alpha + \beta \mu, \beta^2\sigma^2)
\end{displaymath}

As a consequence, if we have a variable $X \sim N(\mu, \sigma^2)$ then we have the identity:

\begin{displaymath}
Z = \frac{X-\mu}{\sigma} \sim N(0,1)
\end{displaymath}
This variable $Z$ is referred to as the \emph{standard normal}.
\end{df}

It is important that we can ``transform'' any given variable to a standard normal because we can very easily make probability statements about the standard normal.   Specifically:

\begin{displaymath}
p[x_1 < X < x_2] = p \left[ \frac{x_1-\mu}{\sigma} < Z < \frac{x_2 -\mu}{\sigma} \right]
\end{displaymath}

We can easily obtain (via printed tables or the computer) values for $p[X \leq x]$ for the Normal distribution, as illustrated by this figure:
%\begin{center}
%\includegraphics[width=0.25\textwidth]{normtabs}
%\end{center}
Some values for the area under the curve, for integer values of $z$ are given here:

\begin{center}
\begin{tabular}{rr}
  \hline
  $z$ & $p[Z \leq z]$ \\ 
  \hline
 -3 & 0.0013 \\ 
 -2 & 0.0228 \\ 
 -1 & 0.1587 \\ 
  0 & 0.5000 \\ 
  1 & 0.8413 \\ 
  2 & 0.9772 \\ 
  3 & 0.9987 \\ 
   \hline
\end{tabular}
\end{center}


\newpage
\subsubsection{A problem}

If $X \sim N(10,4)$, calculate $P[4 < X < 8]$

We want:
\begin{eqnarray*}
P[4 < X < 8] &=& p \left[ \frac{4-10}{2} < \frac{X-10}{2} < \frac{8-10}{2} \right]\\
&=& P[-3 < Z < -1]\\
&=& P[Z < -1] - P[Z < -3]
\end{eqnarray*}

From the table, we can see that the values we need are $0.1587$ and $0.0013$, hence

\begin{eqnarray*}
P[4 < X < 8] &=& 0.1587-0.0013\\
 &=& 0.1574
\end{eqnarray*}

There are some more detailed tables at the end of the chapter with the problems.

\section{Problems}

\begin{enumerate}
\input{Problems/dummy10/ContinuousExamples_WhichDefinition.tex}
\input{Problems/dummy10/ContinuousExamples_ConstantInt.tex}
\input{Problems/dummy10/ContinuousExamples_FindF.tex}
\input{Problems/dummy10/ContinuousExamples_StandardNormal.tex}
\input{Problems/dummy10/ContinuousExamples_NonStandardNormal.tex}
\input{Problems/dummy10/ContinuousExamples_CoffeeDispenser.tex}
\input{Problems/dummy10/ContinuousExamples_ExpCDF.tex}
\input{Problems/dummy10/ContinuousExamples_ExponentialConcept.tex}
\input{Problems/dummy10/ContinuousExamples_ExpQuantile.tex}
\input{Problems/dummy10/ContinuousExamples_BetaQuantile.tex}
\input{Problems/dummy10/ContinuousExamples_Pareto.tex}
\input{Problems/dummy10/ContinuousExamples_ParetoQuantile.tex}
\input{Problems/dummy10/ContinuousExamples_Rayleigh.tex}
\input{Problems/dummy10/ContinuousExamples_RayleighQuantile.tex}



\end{enumerate}

For further practice pick any problems from 1 to 61 (chapter 5) in Blitzstein and Hwang.   The exam doesn't necessarily have to concentrate on Celebrity Distributions that we have studied in detail in class.   You need to know how to verify a function is a valid PDF and find it's expectation and variance.

\end{document}
